# parallel_v1: arcface + yolo + mediapipe + realsense
# 1. face ìž„ë² ë”© ìƒì„± (ë©€í‹°í”„ë¡œì„¸ì‹± - ê° í”„ë¡œì„¸ìŠ¤ê°€ ê°œë³„ì ìœ¼ë¡œ ëª¨ë¸ ì´ˆê¸°í™”,ë³‘ë ¬ ìž„ë² ë”© ì¶”ì¶œ)
# 2. realsense + yolo + mobilefacenet ë³‘ë ¬ ì²˜ë¦¬ 
# realsense í”„ë ˆìž„ ìº¡ì²˜ - ë©€í‹°ìŠ¤ë ˆë”©
# yolo human detection - ë©€í‹°í”„ë¡œì„¸ì‹±
# ì–¼êµ´ ìž„ë² ë”© ë¹„êµ (ë©€í‹°ìŠ¤ë ˆë”©)
# ì „ì²´ ì‹¤í–‰ - yoloëŠ” ë©€í‹°í”„ë¡œì„¸ì‹±, realsenseì™€ faceëŠ” ë©€í‹°ìŠ¤ë ˆë”©


import cv2
import numpy as np
import os
import insightface
from insightface.app import FaceAnalysis
from concurrent.futures import ProcessPoolExecutor

def init_model():
    """ê° í”„ë¡œì„¸ìŠ¤ì—ì„œ ê°œë³„ì ìœ¼ë¡œ FaceAnalysis ëª¨ë¸ì„ ì´ˆê¸°í™”"""
    global app
    app = FaceAnalysis(name="buffalo_sc")  # MobileFaceNet ê³„ì—´
    app.prepare(ctx_id=0, det_size=(640, 640))  # ðŸ”¹ GPU ëª¨ë“œ ì‚¬ìš©

def get_mobileface_embedding(image_path):
    """ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•˜ì—¬ MobileFaceNet ìž„ë² ë”©ì„ ì¶”ì¶œ"""
    img_bgr = cv2.imread(image_path)
    if img_bgr is None:
        return None
    faces = app.get(img_bgr)
    if len(faces) == 0:
        return None
    return faces[0].embedding

def process_image(file, folder):
    """ê° í”„ë¡œì„¸ìŠ¤ì—ì„œ ì‹¤í–‰ë  í•¨ìˆ˜ (my_face_folderë¥¼ ì¸ìžë¡œ ë°›ìŒ)"""
    init_model()  # ðŸ”¹ ê° í”„ë¡œì„¸ìŠ¤ì—ì„œ MobileFaceNet ëª¨ë¸ì„ ê°œë³„ì ìœ¼ë¡œ ì´ˆê¸°í™”
    path = os.path.join(folder, file)
    if file.lower().endswith(('.jpg', '.png', '.jpeg')):
        return get_mobileface_embedding(path)
    return None

if __name__ == "__main__":
    my_face_folder = "C:/myface"
    image_files = [file for file in os.listdir(my_face_folder) if file.lower().endswith(('.jpg', '.png', '.jpeg'))]
    
    embeddings = []
    with ProcessPoolExecutor() as executor:
        results = executor.map(process_image, image_files, [my_face_folder] * len(image_files))  # ðŸ”¹ ì¸ìžë¡œ ì „ë‹¬

        for emb in results:
            if emb is not None:
                embeddings.append(emb)

    if len(embeddings) == 0:
        raise ValueError("No embeddings generated from MobileFaceNet.")

    avg_embedding = np.mean(embeddings, axis=0)
    print("MobileFaceNet embedding shape:", avg_embedding.shape)
    
    np.save("my_mobileface_embedding.npy", avg_embedding)
    print("Saved my_mobileface_embedding.npy")


import cv2
import mediapipe as mp
import time
import torch
import numpy as np
import warnings
import threading
import multiprocessing as mp_process
from queue import Queue

from ultralytics import YOLO
from sklearn.metrics.pairwise import cosine_similarity
import pyrealsense2 as rs
import insightface
from insightface.app import FaceAnalysis

############################
# (A) RealSense í”„ë ˆìž„ ìº¡ì²˜ë¥¼ ë³„ë„ì˜ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
############################
class RealSenseCapture(threading.Thread):
    def __init__(self, queue):
        super().__init__()
        self.queue = queue
        self.pipeline = rs.pipeline()
        config = rs.config()
        config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)
        config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)
        self.pipeline.start(config)
        self.running = True

    def run(self):
        while self.running:
            frames = self.pipeline.wait_for_frames()
            color_frame = frames.get_color_frame()
            depth_frame = frames.get_depth_frame()
            if color_frame and depth_frame:
                self.queue.put((color_frame, depth_frame))

    def stop(self):
        self.running = False
        self.pipeline.stop()

############################
# (B) YOLOë¥¼ ë©€í‹°í”„ë¡œì„¸ì‹±ìœ¼ë¡œ ì‹¤í–‰
############################
def process_detection(input_queue, output_queue, model_path):
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    model = YOLO(model_path).to(device)
    
    while True:
        frame = input_queue.get()
        if frame is None:
            break
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = model(rgb_frame, conf=0.5)
        
        det = results[0]
        boxes = det.boxes
        
        person_detections = []
        for box in boxes:
            x1, y1, x2, y2 = map(int, box.xyxy[0])
            class_id = int(box.cls[0])
            conf = float(box.conf[0])
            if class_id == 0:  # ì‚¬ëžŒë§Œ íƒì§€
                w, h = x2 - x1, y2 - y1
                person_detections.append(((x1, y1, w, h), conf, 0))
        
        output_queue.put(person_detections)

############################
# (C) MobileFaceNet ë³‘ë ¬í™”
############################
class FaceEmbeddingProcessor(threading.Thread):
    def __init__(self, input_queue, output_queue, my_face_embedding):
        super().__init__()
        self.input_queue = input_queue
        self.output_queue = output_queue
        self.my_face_embedding = my_face_embedding
        self.app = FaceAnalysis(name="buffalo_sc")
        self.app.prepare(ctx_id=0, det_size=(640, 640))
        self.running = True

    def run(self):
        while self.running:
            data = self.input_queue.get()
            if data is None:
                break
            tid, face_crop = data
            embedding = self.get_mobileface_embedding(face_crop)
            if embedding is not None:
                same_person, sim = self.is_my_face(embedding, self.my_face_embedding, threshold=0.4)
                self.output_queue.put((tid, same_person, sim))

    def get_mobileface_embedding(self, image_bgr):
        faces = self.app.get(image_bgr)
        return faces[0].embedding if faces else None

    def is_my_face(self, face_embedding, my_embedding, threshold=0.4):
        sim = cosine_similarity([face_embedding], [my_embedding])[0][0]
        return sim > threshold, sim

    def stop(self):
        self.running = False

############################
# (D) ë©”ì¸ ì‹¤í–‰
############################
if __name__ == "__main__":
    frame_queue = Queue()
    detection_input_queue = mp_process.Queue()
    detection_output_queue = mp_process.Queue()
    face_input_queue = Queue()
    face_output_queue = Queue()
    
    # RealSense í”„ë ˆìž„ ìº¡ì²˜ ì‹œìž‘
    realsense_capture = RealSenseCapture(frame_queue)
    realsense_capture.start()
    
    # YOLO í”„ë¡œì„¸ìŠ¤ ì‹œìž‘
    detection_process = mp_process.Process(target=process_detection, args=(detection_input_queue, detection_output_queue, "C:/epoch180.pt"))
    detection_process.start()
    
    # MobileFaceNet ìŠ¤ë ˆë“œ ì‹œìž‘
    my_face_embedding = np.load("my_mobileface_embedding.npy")
    face_processor = FaceEmbeddingProcessor(face_input_queue, face_output_queue, my_face_embedding)
    face_processor.start()
    
    # OpenCV ìœˆë„ìš° ì„¤ì •
    window_name = "Parallel Processing"
    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)
    cv2.resizeWindow(window_name, 960, 720)
    
    while True:
        if not frame_queue.empty():
            color_frame, depth_frame = frame_queue.get()
            frame = np.asanyarray(color_frame.get_data())
            detection_input_queue.put(frame)
            
            if not detection_output_queue.empty():
                person_detections = detection_output_queue.get()
                for detection in person_detections:
                    x1, y1, w, h = detection[0]
                    face_crop = frame[y1:y1+h, x1:x1+w]
                    if face_crop.size > 0:
                        face_input_queue.put((x1, face_crop))

            while not face_output_queue.empty():
                tid, same_person, sim = face_output_queue.get()
                color = (0, 255, 0) if same_person else (0, 0, 255)
                cv2.putText(frame, f"ID {tid}: {sim:.2f}", (10, 30 + tid * 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
            
            cv2.imshow(window_name, frame)
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
    
    realsense_capture.stop()
    detection_input_queue.put(None)
    detection_process.join()
    face_processor.stop()
    cv2.destroyAllWindows()
