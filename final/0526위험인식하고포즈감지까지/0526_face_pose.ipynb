{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사람 + 총 + 칼 인식\n",
    "pose estimation은 모든 사람에 대해 인식(수정해서 아래 경우에만 적용할 수도 있음)\n",
    "사람과 총 혹은 칼의 bounding box가 겹치는 경우에만 arcface 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#1. 얼굴 학습시키는 부분\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "#1. 얼굴 학습시키는 부분\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from insightface.app import FaceAnalysis\n",
    "\n",
    "def initialize_arcface():\n",
    "    app = FaceAnalysis(name=\"buffalo_l\")  # ArcFace 모델 (buffalo_l은 기본 권장)\n",
    "    app.prepare(ctx_id=-1, det_size=(640, 640))  # GPU: ctx_id=0, CPU: -1\n",
    "    return app\n",
    "\n",
    "def get_face_embedding(app, image_bgr):\n",
    "    # ArcFace의 app.get()은 BGR 형식으로 이미지를 받기도 합니다.\n",
    "    # 만약 RGB가 필요하면 cvtColor로 변환하세요.\n",
    "    faces = app.get(image_bgr)\n",
    "    if len(faces) > 0:\n",
    "        return faces[0].embedding  # 첫 번째 얼굴의 임베딩\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def generate_average_embedding(app, folder_path):\n",
    "    embeddings = []\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            img_path = os.path.join(folder_path, file)\n",
    "            image = cv2.imread(img_path)\n",
    "            if image is None:\n",
    "                print(f\"이미지 로드 실패: {img_path}\")\n",
    "                continue\n",
    "            \n",
    "            embedding = get_face_embedding(app, image)\n",
    "            if embedding is not None:\n",
    "                embeddings.append(embedding)\n",
    "            else:\n",
    "                print(f\"얼굴 검출 실패: {img_path}\")\n",
    "    \n",
    "    if len(embeddings) == 0:\n",
    "        raise ValueError(\"임베딩을 하나도 생성하지 못했습니다.\")\n",
    "    \n",
    "    avg_embedding = np.mean(embeddings, axis=0)\n",
    "    return avg_embedding\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app = initialize_arcface()\n",
    "    # 내 얼굴 사진 폴더\n",
    "    my_face_folder = \"C:myface\"  \n",
    "    my_face_embedding = generate_average_embedding(app, my_face_folder)\n",
    "    np.save(\"my_face_embedding.npy\", my_face_embedding)  # 필요 시 저장\n",
    "    print(\"내 얼굴 평균 임베딩 생성 완료.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from ultralytics import YOLO\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from insightface.app import FaceAnalysis\n",
    "\n",
    "#######################\n",
    "# 1) YOLO + ArcFace 초기화\n",
    "#######################\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# YOLOv8 모델 로드\n",
    "model = YOLO(\"C:/epoch180.pt\").to(device)\n",
    "\n",
    "# ArcFace 초기화\n",
    "arc_app = FaceAnalysis(name=\"buffalo_l\")\n",
    "arc_app.prepare(ctx_id=-1, det_size=(640,640))  # CPU 사용 예시\n",
    "\n",
    "# 내 얼굴 임베딩\n",
    "my_face_embedding = np.load(\"my_face_embedding.npy\")\n",
    "\n",
    "def get_face_embedding(arc_app, face_img_bgr):\n",
    "    faces = arc_app.get(face_img_bgr)\n",
    "    if len(faces) == 0:\n",
    "        return None\n",
    "    return faces[0].embedding\n",
    "\n",
    "def is_my_face(face_embedding, my_embedding, threshold=0.4):\n",
    "    sim = cosine_similarity([face_embedding], [my_embedding])[0][0]\n",
    "    return (sim > threshold), sim\n",
    "\n",
    "#######################\n",
    "# 2) Mediapipe Pose 초기화\n",
    "#######################\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(\n",
    "    static_image_mode=False,\n",
    "    model_complexity=1,\n",
    "    enable_segmentation=False,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# 랜드마크 인덱스 (Mediapipe Pose)\n",
    "LEFT_SHOULDER = 11\n",
    "RIGHT_SHOULDER = 12\n",
    "LEFT_WRIST = 15\n",
    "RIGHT_WRIST = 16\n",
    "\n",
    "def is_arm_raised(shoulder_y, wrist_y, threshold=0.05):\n",
    "    # Mediapipe Pose: y=0 상단, y=1 하단 (작을수록 위)\n",
    "    return wrist_y < (shoulder_y - threshold)\n",
    "\n",
    "#######################\n",
    "# 3) 바운딩박스 overlap(교차) 함수\n",
    "#######################\n",
    "def boxes_overlap(boxA, boxB):\n",
    "    \"\"\"\n",
    "    boxA, boxB = (x1, y1, x2, y2)\n",
    "    단순 교차 여부 판단 (한 픽셀이라도 겹치면 True)\n",
    "    \"\"\"\n",
    "    x1A, y1A, x2A, y2A = boxA\n",
    "    x1B, y1B, x2B, y2B = boxB\n",
    "\n",
    "    # 수평 방향 교차 판단\n",
    "    overlap_x = not (x2A < x1B or x2B < x1A)\n",
    "    # 수직 방향 교차 판단\n",
    "    overlap_y = not (y2A < y1B or y2B < y1A)\n",
    "\n",
    "    return overlap_x and overlap_y\n",
    "\n",
    "#######################\n",
    "# 4) 메인 루프\n",
    "#######################\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"카메라를 열 수 없습니다.\")\n",
    "    exit()\n",
    "\n",
    "prev_time = time.time()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"프레임을 읽어올 수 없습니다.\")\n",
    "        break\n",
    "\n",
    "    # Pose(전신) 추론 (원본 프레임 전체)\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    pose_results = pose.process(rgb)\n",
    "\n",
    "    # 간단 팔 상태 판별\n",
    "    action_text = \"\"\n",
    "    if pose_results.pose_landmarks:\n",
    "        landmarks = pose_results.pose_landmarks.landmark\n",
    "        left_shoulder_y = landmarks[LEFT_SHOULDER].y\n",
    "        right_shoulder_y = landmarks[RIGHT_SHOULDER].y\n",
    "        left_wrist_y = landmarks[LEFT_WRIST].y\n",
    "        right_wrist_y = landmarks[RIGHT_WRIST].y\n",
    "\n",
    "        left_arm_up = is_arm_raised(left_shoulder_y, left_wrist_y, threshold=0.05)\n",
    "        right_arm_up = is_arm_raised(right_shoulder_y, right_wrist_y, threshold=0.05)\n",
    "\n",
    "        if left_arm_up and right_arm_up:\n",
    "            action_text = \"both arms up\"\n",
    "        elif left_arm_up:\n",
    "            action_text = \"left arm up\"\n",
    "        elif right_arm_up:\n",
    "            action_text = \"right arm up\"\n",
    "        else:\n",
    "            action_text = \"do nothing\"\n",
    "\n",
    "        # 전신 랜드마크 시각화\n",
    "        mp_drawing.draw_landmarks(frame, pose_results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "    # 왼쪽 상단에 pose 텍스트 표시 (전체)\n",
    "    cv2.putText(frame, action_text, (30, 50),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 3)\n",
    "\n",
    "    # ---------------------\n",
    "    # YOLO 추론\n",
    "    # ---------------------\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = model(rgb_frame)\n",
    "\n",
    "    # (1) 박스 분류: 사람 vs 무기(총=1, 칼=2)\n",
    "    person_boxes = []\n",
    "    weapon_boxes = []  # 총(1), 칼(2)\n",
    "\n",
    "    for box in results[0].boxes:\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "        class_id = int(box.cls)\n",
    "        conf = float(box.conf)\n",
    "        class_name = model.names[class_id]\n",
    "\n",
    "        # 사람/총/칼 시각화\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0,255,0), 2)\n",
    "        label = f\"{class_name}: {conf:.2f}\"\n",
    "        cv2.putText(frame, label, (x1, y1 - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,0,0), 2)\n",
    "\n",
    "        if class_id == 0: # person\n",
    "            person_boxes.append((x1, y1, x2, y2))\n",
    "        elif class_id in [1, 2]: # gun or knife\n",
    "            weapon_boxes.append((x1, y1, x2, y2))\n",
    "\n",
    "    # (2) 무기와 겹치는 사람만 Arcface 시도\n",
    "    for (px1, py1, px2, py2) in person_boxes:\n",
    "        # 무기와 교차?\n",
    "        overlap_with_weapon = False\n",
    "        for wbox in weapon_boxes:\n",
    "            if boxes_overlap((px1, py1, px2, py2), wbox):\n",
    "                overlap_with_weapon = True\n",
    "                break\n",
    "\n",
    "        if overlap_with_weapon:\n",
    "            # --------------- ArcFace 처리 ---------------\n",
    "            person_crop = frame[py1:py2, px1:px2]  # BGR\n",
    "            if person_crop.size == 0:\n",
    "                continue\n",
    "\n",
    "            face_embedding = get_face_embedding(arc_app, person_crop)\n",
    "            if face_embedding is not None:\n",
    "                same_person, sim = is_my_face(face_embedding, my_face_embedding, threshold=0.4)\n",
    "                if same_person:\n",
    "                    label = f\"Me! (sim={sim:.2f})\"\n",
    "                    color = (0, 255, 0)\n",
    "                else:\n",
    "                    label = f\"Not me (sim={sim:.2f})\"\n",
    "                    color = (0, 0, 255)\n",
    "\n",
    "                cv2.rectangle(frame, (px1, py1), (px2, py2), color, 2)\n",
    "                cv2.putText(frame, label, (px1, py1-10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "    # FPS\n",
    "    current_time = time.time()\n",
    "    fps = 1 / (current_time - prev_time)\n",
    "    prev_time = current_time\n",
    "    cv2.putText(frame, f\"FPS: {fps:.2f}\", (10,30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)\n",
    "\n",
    "    cv2.imshow(\"YOLO_Arcface_MediaPipe_Weapons\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
