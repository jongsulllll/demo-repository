{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<변경점>  \n",
    "\n",
    "buffalo_s 대신 buffalo_sc 사용함. 0.04sec정도 소요됨\n",
    "\n",
    "v2: yolo face model 사용\n",
    "v3: 사람 별로 첫 10프레임씩만 얼굴인식"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 사람 + 총 + 칼 인식    \n",
    "2. Arcface를 사람마다 첫 20프레임 동안 적용(Me, NotME).   \n",
    "3. NotMe이면서 사람과 총 혹은 칼의 bounding box가 겹치는 경우에는 위험인으로 분류 -> 한 번 위험인으로 분류된 사람의 ID는 dangerous_ids로 관리됨 -> dangerous_ids 중 하나에 해당하는 사람은 위에 \"Dangerous person\"이라고 뜸\n",
    "4. pose estimation을 dangerous person에 대해 적용(왼팔들기, 오른팔들기, 양팔들기)  \n",
    "5. 출력화면 사이즈를 키움  \n",
    "6. 버그수정: 초기에 무기와 교차하여 dangerous_ids에 들어갔더라도, ArcFace로 내 얼굴임이 확인되면(=나 자신이 무기를 소지한 상황) 그 사람을 위험 인물에서 제외  \n",
    "7. Kobukki robot이 dangerous_ids 내에 있는 사람을 쫓아가도록 하면 될 듯\n",
    "8. warning 해결: pip install --upgrade albumentations\n",
    "9. 사람인 경우에 segmentation으로 윤곽선 치기(성공)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py:69: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\user/.insightface\\models\\buffalo_s\\1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\user/.insightface\\models\\buffalo_s\\2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\user/.insightface\\models\\buffalo_s\\det_500m.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\user/.insightface\\models\\buffalo_s\\genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\user/.insightface\\models\\buffalo_s\\w600k_mbf.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (640, 640)\n",
      "MobileFaceNet embedding shape: (512,)\n",
      "Saved my_mobileface_embedding.npy\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import insightface\n",
    "from insightface.app import FaceAnalysis\n",
    "\n",
    "# 1) MobileFaceNet 모델(InsightFace) 초기화\n",
    "app = FaceAnalysis(name=\"buffalo_sc\")  # buffalo_s = MobileFaceNet 계열\n",
    "app.prepare(ctx_id=0, det_size=(640,640))  # GPU 사용(ctx_id=0), CPU는 -1\n",
    "\n",
    "def get_mobileface_embedding(image_bgr):\n",
    "    # image_bgr: np.array(BGR)\n",
    "    faces = app.get(image_bgr)\n",
    "    if len(faces)==0:\n",
    "        return None\n",
    "    # 보통 faces[0].embedding shape = (128,) or (512,) 모델에 따라 다름\n",
    "    return faces[0].embedding\n",
    "\n",
    "# 내 얼굴 사진 폴더\n",
    "my_face_folder = \"C:/myface\"\n",
    "embeddings = []\n",
    "\n",
    "for file in os.listdir(my_face_folder):\n",
    "    if file.lower().endswith(('.jpg','.png','.jpeg')):\n",
    "        path = os.path.join(my_face_folder, file)\n",
    "        img_bgr = cv2.imread(path)\n",
    "        if img_bgr is None:\n",
    "            continue\n",
    "        emb = get_mobileface_embedding(img_bgr)\n",
    "        if emb is not None:\n",
    "            embeddings.append(emb)\n",
    "\n",
    "if len(embeddings)==0:\n",
    "    raise ValueError(\"No embeddings generated from MobileFaceNet.\")\n",
    "\n",
    "# 평균 임베딩\n",
    "avg_embedding = np.mean(embeddings, axis=0)\n",
    "print(\"MobileFaceNet embedding shape:\", avg_embedding.shape)\n",
    "\n",
    "# 파일 저장\n",
    "np.save(\"my_mobileface_embedding.npy\", avg_embedding)\n",
    "print(\"Saved my_mobileface_embedding.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py:69: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\user/.insightface\\models\\buffalo_sc\\det_500m.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\user/.insightface\\models\\buffalo_sc\\w600k_mbf.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (640, 640)\n",
      "\n",
      "0: 480x640 1 personnnn, 98.9ms\n",
      "Speed: 16.0ms preprocess, 98.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 128.6ms\n",
      "Speed: 2.5ms preprocess, 128.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "MobileFacenet running time:  0.0\n",
      "\n",
      "0: 480x640 1 personnnn, 100.2ms\n",
      "Speed: 2.0ms preprocess, 100.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 121.7ms\n",
      "Speed: 2.0ms preprocess, 121.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "MobileFacenet running time:  0.0\n",
      "\n",
      "0: 480x640 1 personnnn, 87.0ms\n",
      "Speed: 3.2ms preprocess, 87.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 284.4ms\n",
      "Speed: 2.7ms preprocess, 284.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet for ID 1 (Frame 1/20)\n",
      "MobileFacenet running time:  0.0483090877532959\n",
      "\n",
      "0: 480x640 1 personnnn, 87.4ms\n",
      "Speed: 1.7ms preprocess, 87.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 121.2ms\n",
      "Speed: 3.0ms preprocess, 121.2ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet for ID 1 (Frame 2/20)\n",
      "MobileFacenet running time:  0.04201507568359375\n",
      "\n",
      "0: 480x640 1 personnnn, 95.5ms\n",
      "Speed: 52.7ms preprocess, 95.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 118.2ms\n",
      "Speed: 4.0ms preprocess, 118.2ms inference, 8.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet for ID 1 (Frame 3/20)\n",
      "MobileFacenet running time:  0.03654909133911133\n",
      "\n",
      "0: 480x640 1 personnnn, 96.2ms\n",
      "Speed: 58.0ms preprocess, 96.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 125.8ms\n",
      "Speed: 2.4ms preprocess, 125.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet for ID 1 (Frame 4/20)\n",
      "MobileFacenet running time:  0.04741930961608887\n",
      "\n",
      "0: 480x640 1 personnnn, 94.9ms\n",
      "Speed: 24.6ms preprocess, 94.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 113.2ms\n",
      "Speed: 3.2ms preprocess, 113.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet for ID 1 (Frame 5/20)\n",
      "MobileFacenet running time:  0.0496981143951416\n",
      "\n",
      "0: 480x640 1 personnnn, 86.9ms\n",
      "Speed: 17.5ms preprocess, 86.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 119.9ms\n",
      "Speed: 3.2ms preprocess, 119.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet for ID 1 (Frame 6/20)\n",
      "MobileFacenet running time:  0.0407559871673584\n",
      "\n",
      "0: 480x640 1 personnnn, 88.8ms\n",
      "Speed: 8.3ms preprocess, 88.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 111.4ms\n",
      "Speed: 2.3ms preprocess, 111.4ms inference, 6.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet for ID 1 (Frame 7/20)\n",
      "MobileFacenet running time:  0.04026317596435547\n",
      "\n",
      "0: 480x640 1 personnnn, 96.9ms\n",
      "Speed: 2.8ms preprocess, 96.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 120.2ms\n",
      "Speed: 2.6ms preprocess, 120.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet for ID 1 (Frame 8/20)\n",
      "MobileFacenet running time:  0.040482282638549805\n",
      "\n",
      "0: 480x640 1 personnnn, 89.8ms\n",
      "Speed: 31.7ms preprocess, 89.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 121.6ms\n",
      "Speed: 3.1ms preprocess, 121.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet for ID 1 (Frame 9/20)\n",
      "MobileFacenet running time:  0.04192805290222168\n",
      "\n",
      "0: 480x640 1 personnnn, 131.3ms\n",
      "Speed: 67.6ms preprocess, 131.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 155.7ms\n",
      "Speed: 7.4ms preprocess, 155.7ms inference, 9.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet for ID 1 (Frame 10/20)\n",
      "MobileFacenet running time:  0.03481125831604004\n",
      "\n",
      "0: 480x640 1 personnnn, 93.5ms\n",
      "Speed: 69.0ms preprocess, 93.5ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 125.9ms\n",
      "Speed: 2.9ms preprocess, 125.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "MobileFacenet running time:  0.0\n",
      "\n",
      "0: 480x640 1 personnnn, 85.1ms\n",
      "Speed: 2.1ms preprocess, 85.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 118.2ms\n",
      "Speed: 2.0ms preprocess, 118.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "MobileFacenet running time:  0.0\n",
      "\n",
      "0: 480x640 1 personnnn, 90.7ms\n",
      "Speed: 3.1ms preprocess, 90.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 106.5ms\n",
      "Speed: 3.0ms preprocess, 106.5ms inference, 9.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "MobileFacenet running time:  0.0\n",
      "\n",
      "0: 480x640 1 personnnn, 92.7ms\n",
      "Speed: 2.8ms preprocess, 92.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 138.6ms\n",
      "Speed: 2.0ms preprocess, 138.6ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "MobileFacenet running time:  0.000997304916381836\n",
      "\n",
      "0: 480x640 1 personnnn, 108.8ms\n",
      "Speed: 1.6ms preprocess, 108.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 157.0ms\n",
      "Speed: 2.4ms preprocess, 157.0ms inference, 5.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "MobileFacenet running time:  0.0\n",
      "\n",
      "0: 480x640 1 personnnn, 128.7ms\n",
      "Speed: 3.0ms preprocess, 128.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 123.9ms\n",
      "Speed: 2.9ms preprocess, 123.9ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "MobileFacenet running time:  0.0\n",
      "\n",
      "0: 480x640 1 personnnn, 89.4ms\n",
      "Speed: 3.3ms preprocess, 89.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 111.5ms\n",
      "Speed: 2.0ms preprocess, 111.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "MobileFacenet running time:  0.0009975433349609375\n",
      "\n",
      "0: 480x640 1 personnnn, 281.2ms\n",
      "Speed: 3.0ms preprocess, 281.2ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 117.2ms\n",
      "Speed: 3.0ms preprocess, 117.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "MobileFacenet running time:  0.0\n",
      "\n",
      "0: 480x640 1 personnnn, 90.2ms\n",
      "Speed: 3.1ms preprocess, 90.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 120.2ms\n",
      "Speed: 3.0ms preprocess, 120.2ms inference, 5.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "MobileFacenet running time:  0.0\n",
      "\n",
      "0: 480x640 1 personnnn, 99.6ms\n",
      "Speed: 3.2ms preprocess, 99.6ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 131.3ms\n",
      "Speed: 2.3ms preprocess, 131.3ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "MobileFacenet running time:  0.0\n",
      "\n",
      "0: 480x640 1 personnnn, 95.5ms\n",
      "Speed: 4.4ms preprocess, 95.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 130.9ms\n",
      "Speed: 2.5ms preprocess, 130.9ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "MobileFacenet running time:  0.0\n",
      "\n",
      "0: 480x640 1 personnnn, 96.4ms\n",
      "Speed: 3.3ms preprocess, 96.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 111.9ms\n",
      "Speed: 3.1ms preprocess, 111.9ms inference, 6.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "MobileFacenet running time:  0.0\n",
      "\n",
      "0: 480x640 1 personnnn, 88.7ms\n",
      "Speed: 3.5ms preprocess, 88.7ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 123.1ms\n",
      "Speed: 3.0ms preprocess, 123.1ms inference, 6.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "MobileFacenet running time:  0.0\n",
      "\n",
      "0: 480x640 1 personnnn, 92.5ms\n",
      "Speed: 1.0ms preprocess, 92.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 119.1ms\n",
      "Speed: 2.0ms preprocess, 119.1ms inference, 8.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "MobileFacenet running time:  0.0\n",
      "\n",
      "0: 480x640 1 personnnn, 89.9ms\n",
      "Speed: 2.5ms preprocess, 89.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 129.3ms\n",
      "Speed: 3.1ms preprocess, 129.3ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "MobileFacenet running time:  0.0\n",
      "\n",
      "0: 480x640 1 personnnn, 93.9ms\n",
      "Speed: 2.0ms preprocess, 93.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 136.4ms\n",
      "Speed: 3.5ms preprocess, 136.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "MobileFacenet running time:  0.0\n",
      "\n",
      "0: 480x640 1 personnnn, 90.5ms\n",
      "Speed: 3.1ms preprocess, 90.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 122.6ms\n",
      "Speed: 3.0ms preprocess, 122.6ms inference, 3.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "MobileFacenet running time:  0.0\n",
      "\n",
      "0: 480x640 1 personnnn, 109.0ms\n",
      "Speed: 3.0ms preprocess, 109.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 148.8ms\n",
      "Speed: 3.3ms preprocess, 148.8ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "MobileFacenet running time:  0.0\n",
      "\n",
      "0: 480x640 1 personnnn, 91.7ms\n",
      "Speed: 2.0ms preprocess, 91.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 110.8ms\n",
      "Speed: 2.6ms preprocess, 110.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "MobileFacenet running time:  0.0\n",
      "\n",
      "0: 480x640 1 personnnn, 94.2ms\n",
      "Speed: 2.3ms preprocess, 94.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 124.1ms\n",
      "Speed: 2.0ms preprocess, 124.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "MobileFacenet running time:  0.0\n",
      "\n",
      "0: 480x640 1 personnnn, 107.4ms\n",
      "Speed: 2.0ms preprocess, 107.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 139.4ms\n",
      "Speed: 3.9ms preprocess, 139.4ms inference, 4.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "MobileFacenet running time:  0.0\n",
      "\n",
      "0: 480x640 1 personnnn, 103.3ms\n",
      "Speed: 3.0ms preprocess, 103.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 130.6ms\n",
      "Speed: 2.6ms preprocess, 130.6ms inference, 3.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "MobileFacenet running time:  0.0\n",
      "\n",
      "0: 480x640 1 personnnn, 95.4ms\n",
      "Speed: 3.2ms preprocess, 95.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 149.4ms\n",
      "Speed: 2.8ms preprocess, 149.4ms inference, 5.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "MobileFacenet running time:  0.0\n",
      "\n",
      "0: 480x640 1 personnnn, 113.7ms\n",
      "Speed: 3.2ms preprocess, 113.7ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 132.9ms\n",
      "Speed: 3.0ms preprocess, 132.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "MobileFacenet running time:  0.0\n",
      "\n",
      "0: 480x640 1 personnnn, 94.1ms\n",
      "Speed: 0.5ms preprocess, 94.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 118.2ms\n",
      "Speed: 3.0ms preprocess, 118.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "MobileFacenet running time:  0.0\n",
      "\n",
      "0: 480x640 1 personnnn, 87.7ms\n",
      "Speed: 3.0ms preprocess, 87.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 119.3ms\n",
      "Speed: 2.0ms preprocess, 119.3ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "MobileFacenet running time:  0.0\n",
      "\n",
      "0: 480x640 1 personnnn, 89.0ms\n",
      "Speed: 3.4ms preprocess, 89.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 120.8ms\n",
      "Speed: 3.7ms preprocess, 120.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "MobileFacenet running time:  0.0\n",
      "\n",
      "0: 480x640 1 personnnn, 91.6ms\n",
      "Speed: 2.0ms preprocess, 91.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 115.7ms\n",
      "Speed: 3.0ms preprocess, 115.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "MobileFacenet running time:  0.0\n",
      "\n",
      "0: 480x640 1 personnnn, 89.9ms\n",
      "Speed: 2.1ms preprocess, 89.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 116.0ms\n",
      "Speed: 3.3ms preprocess, 116.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "MobileFacenet running time:  0.0\n",
      "\n",
      "0: 480x640 1 personnnn, 269.7ms\n",
      "Speed: 2.4ms preprocess, 269.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 124.2ms\n",
      "Speed: 2.0ms preprocess, 124.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "MobileFacenet running time:  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.04199957847595215\n",
      "\n",
      "0: 480x640 1 personnnn, 106.0ms\n",
      "Speed: 4.0ms preprocess, 106.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 131.0ms\n",
      "Speed: 2.0ms preprocess, 131.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.039997100830078125\n",
      "\n",
      "0: 480x640 1 personnnn, 85.0ms\n",
      "Speed: 3.0ms preprocess, 85.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 109.0ms\n",
      "Speed: 2.0ms preprocess, 109.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.042998313903808594\n",
      "\n",
      "0: 480x640 1 personnnn, 112.0ms\n",
      "Speed: 13.0ms preprocess, 112.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 114.0ms\n",
      "Speed: 3.0ms preprocess, 114.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.04100799560546875\n",
      "\n",
      "0: 480x640 1 personnnn, 84.0ms\n",
      "Speed: 2.0ms preprocess, 84.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 118.5ms\n",
      "Speed: 2.0ms preprocess, 118.5ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.04199862480163574\n",
      "\n",
      "0: 480x640 1 personnnn, 101.0ms\n",
      "Speed: 17.0ms preprocess, 101.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 121.0ms\n",
      "Speed: 3.0ms preprocess, 121.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.0410001277923584\n",
      "\n",
      "0: 480x640 1 personnnn, 85.5ms\n",
      "Speed: 2.0ms preprocess, 85.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 397.1ms\n",
      "Speed: 2.0ms preprocess, 397.1ms inference, 14.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.05002236366271973\n",
      "\n",
      "0: 480x640 1 personnnn, 220.0ms\n",
      "Speed: 27.0ms preprocess, 220.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 396.5ms\n",
      "Speed: 11.0ms preprocess, 396.5ms inference, 13.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.04500555992126465\n",
      "\n",
      "0: 480x640 1 personnnn, 99.0ms\n",
      "Speed: 7.0ms preprocess, 99.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 256.0ms\n",
      "Speed: 2.0ms preprocess, 256.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.057006120681762695\n",
      "\n",
      "0: 480x640 1 personnnn, 110.0ms\n",
      "Speed: 2.0ms preprocess, 110.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 167.2ms\n",
      "Speed: 2.0ms preprocess, 167.2ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.048004865646362305\n",
      "\n",
      "0: 480x640 1 personnnn, 124.6ms\n",
      "Speed: 8.0ms preprocess, 124.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 165.6ms\n",
      "Speed: 1.0ms preprocess, 165.6ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.04600167274475098\n",
      "\n",
      "0: 480x640 1 personnnn, 103.0ms\n",
      "Speed: 9.0ms preprocess, 103.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 136.0ms\n",
      "Speed: 3.0ms preprocess, 136.0ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.04500293731689453\n",
      "\n",
      "0: 480x640 1 personnnn, 161.9ms\n",
      "Speed: 8.0ms preprocess, 161.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 168.0ms\n",
      "Speed: 3.0ms preprocess, 168.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.04300332069396973\n",
      "\n",
      "0: 480x640 1 personnnn, 91.6ms\n",
      "Speed: 10.0ms preprocess, 91.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 136.0ms\n",
      "Speed: 2.0ms preprocess, 136.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.04700350761413574\n",
      "\n",
      "0: 480x640 1 personnnn, 103.0ms\n",
      "Speed: 14.0ms preprocess, 103.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 147.0ms\n",
      "Speed: 3.0ms preprocess, 147.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.04600405693054199\n",
      "\n",
      "0: 480x640 1 personnnn, 98.0ms\n",
      "Speed: 15.0ms preprocess, 98.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 112.0ms\n",
      "Speed: 2.0ms preprocess, 112.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.046000003814697266\n",
      "\n",
      "0: 480x640 1 personnnn, 88.0ms\n",
      "Speed: 10.0ms preprocess, 88.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 128.9ms\n",
      "Speed: 1.0ms preprocess, 128.9ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.04500150680541992\n",
      "\n",
      "0: 480x640 1 personnnn, 99.0ms\n",
      "Speed: 3.0ms preprocess, 99.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 126.7ms\n",
      "Speed: 4.0ms preprocess, 126.7ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.041997671127319336\n",
      "\n",
      "0: 480x640 1 personnnn, 85.0ms\n",
      "Speed: 4.0ms preprocess, 85.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 108.0ms\n",
      "Speed: 2.0ms preprocess, 108.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.049997806549072266\n",
      "\n",
      "0: 480x640 1 personnnn, 103.0ms\n",
      "Speed: 6.0ms preprocess, 103.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 125.0ms\n",
      "Speed: 2.0ms preprocess, 125.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.044002532958984375\n",
      "\n",
      "0: 480x640 1 personnnn, 97.0ms\n",
      "Speed: 3.0ms preprocess, 97.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 109.0ms\n",
      "Speed: 2.0ms preprocess, 109.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.0410003662109375\n",
      "\n",
      "0: 480x640 1 personnnn, 98.0ms\n",
      "Speed: 20.0ms preprocess, 98.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 123.5ms\n",
      "Speed: 3.0ms preprocess, 123.5ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.043007612228393555\n",
      "\n",
      "0: 480x640 1 personnnn, 101.0ms\n",
      "Speed: 5.0ms preprocess, 101.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 123.2ms\n",
      "Speed: 2.0ms preprocess, 123.2ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.10401201248168945\n",
      "\n",
      "0: 480x640 1 personnnn, 80.8ms\n",
      "Speed: 8.0ms preprocess, 80.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 149.0ms\n",
      "Speed: 1.0ms preprocess, 149.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.04400157928466797\n",
      "\n",
      "0: 480x640 1 personnnn, 96.0ms\n",
      "Speed: 3.0ms preprocess, 96.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 150.0ms\n",
      "Speed: 3.0ms preprocess, 150.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.04868054389953613\n",
      "\n",
      "0: 480x640 1 personnnn, 105.0ms\n",
      "Speed: 19.0ms preprocess, 105.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 130.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 2.0ms preprocess, 130.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.04800248146057129\n",
      "\n",
      "0: 480x640 1 personnnn, 102.0ms\n",
      "Speed: 7.0ms preprocess, 102.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 119.7ms\n",
      "Speed: 2.0ms preprocess, 119.7ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.04300427436828613\n",
      "\n",
      "0: 480x640 1 personnnn, 90.0ms\n",
      "Speed: 7.0ms preprocess, 90.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 123.3ms\n",
      "Speed: 2.0ms preprocess, 123.3ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.040996551513671875\n",
      "\n",
      "0: 480x640 1 personnnn, 87.0ms\n",
      "Speed: 3.0ms preprocess, 87.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 126.4ms\n",
      "Speed: 2.0ms preprocess, 126.4ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.044997215270996094\n",
      "\n",
      "0: 480x640 1 personnnn, 92.0ms\n",
      "Speed: 3.0ms preprocess, 92.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 111.0ms\n",
      "Speed: 3.0ms preprocess, 111.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.04300284385681152\n",
      "\n",
      "0: 480x640 1 personnnn, 94.0ms\n",
      "Speed: 7.0ms preprocess, 94.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 111.0ms\n",
      "Speed: 2.0ms preprocess, 111.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.04000449180603027\n",
      "\n",
      "0: 480x640 1 personnnn, 84.0ms\n",
      "Speed: 10.0ms preprocess, 84.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 139.0ms\n",
      "Speed: 4.0ms preprocess, 139.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.04200243949890137\n",
      "\n",
      "0: 480x640 1 personnnn, 91.0ms\n",
      "Speed: 5.0ms preprocess, 91.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 127.0ms\n",
      "Speed: 2.0ms preprocess, 127.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.045004844665527344\n",
      "\n",
      "0: 480x640 1 personnnn, 120.9ms\n",
      "Speed: 15.0ms preprocess, 120.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 118.5ms\n",
      "Speed: 2.0ms preprocess, 118.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.04099893569946289\n",
      "\n",
      "0: 480x640 1 personnnn, 105.0ms\n",
      "Speed: 21.0ms preprocess, 105.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 139.0ms\n",
      "Speed: 3.0ms preprocess, 139.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.0429997444152832\n",
      "\n",
      "0: 480x640 1 personnnn, 95.0ms\n",
      "Speed: 3.0ms preprocess, 95.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 120.0ms\n",
      "Speed: 1.5ms preprocess, 120.0ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.04199790954589844\n",
      "\n",
      "0: 480x640 1 personnnn, 97.7ms\n",
      "Speed: 11.0ms preprocess, 97.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 115.0ms\n",
      "Speed: 2.0ms preprocess, 115.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.03996706008911133\n",
      "\n",
      "0: 480x640 1 personnnn, 94.0ms\n",
      "Speed: 7.0ms preprocess, 94.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 117.0ms\n",
      "Speed: 2.0ms preprocess, 117.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.04204821586608887\n",
      "\n",
      "0: 480x640 1 personnnn, 94.0ms\n",
      "Speed: 9.0ms preprocess, 94.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 118.0ms\n",
      "Speed: 3.0ms preprocess, 118.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.04700613021850586\n",
      "\n",
      "0: 480x640 1 personnnn, 94.5ms\n",
      "Speed: 3.0ms preprocess, 94.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 111.0ms\n",
      "Speed: 2.0ms preprocess, 111.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.04099893569946289\n",
      "\n",
      "0: 480x640 1 personnnn, 93.0ms\n",
      "Speed: 4.0ms preprocess, 93.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 126.0ms\n",
      "Speed: 3.0ms preprocess, 126.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.045999765396118164\n",
      "\n",
      "0: 480x640 1 personnnn, 86.0ms\n",
      "Speed: 11.0ms preprocess, 86.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 119.0ms\n",
      "Speed: 3.0ms preprocess, 119.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.04300236701965332\n",
      "\n",
      "0: 480x640 1 personnnn, 116.0ms\n",
      "Speed: 5.0ms preprocess, 116.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 129.0ms\n",
      "Speed: 2.0ms preprocess, 129.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.04400014877319336\n",
      "\n",
      "0: 480x640 1 personnnn, 115.0ms\n",
      "Speed: 11.0ms preprocess, 115.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 110.8ms\n",
      "Speed: 2.0ms preprocess, 110.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.03900766372680664\n",
      "\n",
      "0: 480x640 1 personnnn, 114.0ms\n",
      "Speed: 13.0ms preprocess, 114.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 120.0ms\n",
      "Speed: 2.0ms preprocess, 120.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.04400014877319336\n",
      "\n",
      "0: 480x640 1 personnnn, 88.6ms\n",
      "Speed: 4.0ms preprocess, 88.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 118.0ms\n",
      "Speed: 2.0ms preprocess, 118.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.04202604293823242\n",
      "\n",
      "0: 480x640 1 personnnn, 108.0ms\n",
      "Speed: 3.0ms preprocess, 108.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 129.0ms\n",
      "Speed: 2.0ms preprocess, 129.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.04199624061584473\n",
      "\n",
      "0: 480x640 1 personnnn, 97.0ms\n",
      "Speed: 5.0ms preprocess, 97.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 116.1ms\n",
      "Speed: 2.0ms preprocess, 116.1ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.04099559783935547\n",
      "\n",
      "0: 480x640 1 personnnn, 88.0ms\n",
      "Speed: 13.0ms preprocess, 88.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 133.0ms\n",
      "Speed: 2.0ms preprocess, 133.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.04099845886230469\n",
      "\n",
      "0: 480x640 1 personnnn, 107.0ms\n",
      "Speed: 4.0ms preprocess, 107.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 115.0ms\n",
      "Speed: 2.0ms preprocess, 115.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.04500102996826172\n",
      "\n",
      "0: 480x640 1 personnnn, 106.6ms\n",
      "Speed: 3.0ms preprocess, 106.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 person, 129.0ms\n",
      "Speed: 2.0ms preprocess, 129.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.04300522804260254\n",
      "\n",
      "0: 480x640 1 personnnn, 87.0ms\n",
      "Speed: 5.0ms preprocess, 87.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 121.0ms\n",
      "Speed: 2.0ms preprocess, 121.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.04200172424316406\n",
      "\n",
      "0: 480x640 1 personnnn, 108.0ms\n",
      "Speed: 3.0ms preprocess, 108.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 120.8ms\n",
      "Speed: 1.0ms preprocess, 120.8ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.043000221252441406\n",
      "\n",
      "0: 480x640 1 personnnn, 118.1ms\n",
      "Speed: 2.0ms preprocess, 118.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 139.0ms\n",
      "Speed: 4.0ms preprocess, 139.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.04100775718688965\n",
      "\n",
      "0: 480x640 1 personnnn, 87.0ms\n",
      "Speed: 8.0ms preprocess, 87.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 116.0ms\n",
      "Speed: 1.0ms preprocess, 116.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.039003849029541016\n",
      "\n",
      "0: 480x640 1 personnnn, 98.0ms\n",
      "Speed: 10.0ms preprocess, 98.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 113.0ms\n",
      "Speed: 2.0ms preprocess, 113.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.04688858985900879\n",
      "\n",
      "0: 480x640 1 personnnn, 141.0ms\n",
      "Speed: 18.0ms preprocess, 141.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 125.0ms\n",
      "Speed: 2.0ms preprocess, 125.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.04601025581359863\n",
      "\n",
      "0: 480x640 1 personnnn, 91.8ms\n",
      "Speed: 2.0ms preprocess, 91.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 117.0ms\n",
      "Speed: 1.0ms preprocess, 117.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.0429995059967041\n",
      "\n",
      "0: 480x640 1 personnnn, 104.0ms\n",
      "Speed: 9.0ms preprocess, 104.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 125.7ms\n",
      "Speed: 2.0ms preprocess, 125.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.04700207710266113\n",
      "\n",
      "0: 480x640 1 personnnn, 89.0ms\n",
      "Speed: 3.0ms preprocess, 89.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 102.8ms\n",
      "Speed: 2.0ms preprocess, 102.8ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.03999972343444824\n",
      "\n",
      "0: 480x640 1 personnnn, 102.5ms\n",
      "Speed: 11.0ms preprocess, 102.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 122.0ms\n",
      "Speed: 2.0ms preprocess, 122.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.04499983787536621\n",
      "\n",
      "0: 480x640 1 personnnn, 103.0ms\n",
      "Speed: 3.0ms preprocess, 103.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 121.6ms\n",
      "Speed: 1.0ms preprocess, 121.6ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.043006181716918945\n",
      "\n",
      "0: 480x640 1 personnnn, 106.0ms\n",
      "Speed: 2.0ms preprocess, 106.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 106.0ms\n",
      "Speed: 2.0ms preprocess, 106.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.04000043869018555\n",
      "\n",
      "0: 480x640 1 personnnn, 99.4ms\n",
      "Speed: 11.0ms preprocess, 99.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.7ms\n",
      "Speed: 2.0ms preprocess, 142.7ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.04700350761413574\n",
      "\n",
      "0: 480x640 1 personnnn, 99.0ms\n",
      "Speed: 3.0ms preprocess, 99.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 118.0ms\n",
      "Speed: 1.0ms preprocess, 118.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.04600095748901367\n",
      "\n",
      "0: 480x640 1 personnnn, 99.0ms\n",
      "Speed: 2.0ms preprocess, 99.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 110.0ms\n",
      "Speed: 3.0ms preprocess, 110.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.04200100898742676\n",
      "\n",
      "0: 480x640 1 personnnn, 92.0ms\n",
      "Speed: 5.0ms preprocess, 92.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.0ms\n",
      "Speed: 2.0ms preprocess, 144.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.040004730224609375\n",
      "\n",
      "0: 480x640 1 personnnn, 104.0ms\n",
      "Speed: 2.0ms preprocess, 104.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 113.0ms\n",
      "Speed: 2.0ms preprocess, 113.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.044003963470458984\n",
      "\n",
      "0: 480x640 1 personnnn, 115.8ms\n",
      "Speed: 9.0ms preprocess, 115.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 109.0ms\n",
      "Speed: 2.0ms preprocess, 109.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.04100298881530762\n",
      "\n",
      "0: 480x640 1 personnnn, 98.0ms\n",
      "Speed: 11.0ms preprocess, 98.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 129.0ms\n",
      "Speed: 2.0ms preprocess, 129.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.04199981689453125\n",
      "\n",
      "0: 480x640 1 personnnn, 99.0ms\n",
      "Speed: 9.0ms preprocess, 99.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 122.0ms\n",
      "Speed: 1.0ms preprocess, 122.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.04700589179992676\n",
      "\n",
      "0: 480x640 1 personnnn, 89.0ms\n",
      "Speed: 13.0ms preprocess, 89.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 113.8ms\n",
      "Speed: 2.0ms preprocess, 113.8ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.04200148582458496\n",
      "\n",
      "0: 480x640 1 personnnn, 109.0ms\n",
      "Speed: 6.0ms preprocess, 109.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 110.0ms\n",
      "Speed: 2.0ms preprocess, 110.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.040999412536621094\n",
      "\n",
      "0: 480x640 1 personnnn, 109.0ms\n",
      "Speed: 10.0ms preprocess, 109.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 128.0ms\n",
      "Speed: 3.0ms preprocess, 128.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.04199862480163574\n",
      "\n",
      "0: 480x640 1 personnnn, 100.0ms\n",
      "Speed: 4.0ms preprocess, 100.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 112.0ms\n",
      "Speed: 2.0ms preprocess, 112.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.04100203514099121\n",
      "\n",
      "0: 480x640 1 personnnn, 104.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 17.0ms preprocess, 104.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 119.0ms\n",
      "Speed: 2.0ms preprocess, 119.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.040992021560668945\n",
      "\n",
      "0: 480x640 1 personnnn, 101.0ms\n",
      "Speed: 2.0ms preprocess, 101.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 134.0ms\n",
      "Speed: 2.0ms preprocess, 134.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.049001455307006836\n",
      "\n",
      "0: 480x640 1 personnnn, 95.0ms\n",
      "Speed: 18.0ms preprocess, 95.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 107.0ms\n",
      "Speed: 2.0ms preprocess, 107.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.04200315475463867\n",
      "\n",
      "0: 480x640 1 personnnn, 85.3ms\n",
      "Speed: 10.0ms preprocess, 85.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 129.0ms\n",
      "Speed: 2.0ms preprocess, 129.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.04400205612182617\n",
      "\n",
      "0: 480x640 1 personnnn, 99.0ms\n",
      "Speed: 9.0ms preprocess, 99.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 121.8ms\n",
      "Speed: 2.0ms preprocess, 121.8ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.04401683807373047\n",
      "\n",
      "0: 480x640 1 personnnn, 107.0ms\n",
      "Speed: 11.0ms preprocess, 107.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 117.0ms\n",
      "Speed: 2.0ms preprocess, 117.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.04300045967102051\n",
      "\n",
      "0: 480x640 1 personnnn, 111.0ms\n",
      "Speed: 8.0ms preprocess, 111.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 125.0ms\n",
      "Speed: 2.0ms preprocess, 125.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.04799938201904297\n",
      "\n",
      "0: 480x640 1 personnnn, 98.0ms\n",
      "Speed: 5.0ms preprocess, 98.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 117.0ms\n",
      "Speed: 2.0ms preprocess, 117.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.04500532150268555\n",
      "\n",
      "0: 480x640 1 personnnn, 98.0ms\n",
      "Speed: 10.0ms preprocess, 98.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 117.0ms\n",
      "Speed: 2.0ms preprocess, 117.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.05000138282775879\n",
      "\n",
      "0: 480x640 1 personnnn, 96.0ms\n",
      "Speed: 3.0ms preprocess, 96.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 117.5ms\n",
      "Speed: 2.0ms preprocess, 117.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.0410003662109375\n",
      "\n",
      "0: 480x640 1 personnnn, 120.0ms\n",
      "Speed: 7.0ms preprocess, 120.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 131.6ms\n",
      "Speed: 5.0ms preprocess, 131.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.04099845886230469\n",
      "\n",
      "0: 480x640 1 personnnn, 124.0ms\n",
      "Speed: 28.0ms preprocess, 124.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 119.7ms\n",
      "Speed: 2.0ms preprocess, 119.7ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.040995121002197266\n",
      "\n",
      "0: 480x640 1 personnnn, 90.6ms\n",
      "Speed: 6.0ms preprocess, 90.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 114.0ms\n",
      "Speed: 2.0ms preprocess, 114.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Running MobileFacenet...\n",
      "MobileFacenet running time:  0.03699946403503418\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from ultralytics import YOLO\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "\n",
    "############################\n",
    "# (A) MobileFaceNet (InsightFace) 준비\n",
    "############################\n",
    "import insightface\n",
    "from insightface.app import FaceAnalysis\n",
    "\n",
    "app = FaceAnalysis(name=\"buffalo_sc\")  # \"buffalo_m\"은 MobileFaceNet 기반\n",
    "app.prepare(ctx_id=0, det_size=(640,640))  # GPU라면 ctx_id=0, CPU는 -1\n",
    "\n",
    "def get_mobileface_embedding(image_bgr):\n",
    "    if image_bgr is None or image_bgr.size==0:\n",
    "        return None\n",
    "    faces = app.get(image_bgr)\n",
    "    if len(faces)==0:\n",
    "        return None\n",
    "    return faces[0].embedding  # shape 예: (128,)\n",
    "\n",
    "def is_my_face(face_embedding, my_embedding, threshold=0.4):\n",
    "    sim = cosine_similarity([face_embedding], [my_embedding])[0][0]\n",
    "    return (sim > threshold), sim\n",
    "\n",
    "############################\n",
    "# (B) 모델/함수 초기화\n",
    "############################\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = YOLO(\"C:/epoch180.pt\").to(device)\n",
    "model_seg = YOLO(\"yolov8n-seg.pt\").to(device)\n",
    "\n",
    "# MobileFaceNet 임베딩\n",
    "my_face_embedding = np.load(\"my_mobileface_embedding.npy\")  # (128,) or (512,) etc.\n",
    "\n",
    "############################\n",
    "# (C) Mediapipe Pose 등 동일\n",
    "############################\n",
    "mp_pose = mp.solutions.pose\n",
    "pose_danger = mp_pose.Pose(\n",
    "    static_image_mode=True,\n",
    "    model_complexity=1,\n",
    "    enable_segmentation=False,\n",
    "    min_detection_confidence=0.7,\n",
    "    min_tracking_confidence=0.7\n",
    ")\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "LEFT_SHOULDER = 11\n",
    "RIGHT_SHOULDER= 12\n",
    "LEFT_WRIST   = 15\n",
    "RIGHT_WRIST  = 16\n",
    "\n",
    "def is_arm_raised(shoulder_y, wrist_y, threshold=0.05):\n",
    "    return wrist_y < (shoulder_y - threshold)\n",
    "\n",
    "def boxes_overlap(boxA, boxB):\n",
    "    (x1A, y1A, x2A, y2A) = boxA\n",
    "    (x1B, y1B, x2B, y2B) = boxB\n",
    "    overlap_x = not (x2A < x1B or x2B < x1A)\n",
    "    overlap_y = not (y2A < y1B or y2B < y1A)\n",
    "    return overlap_x and overlap_y\n",
    "\n",
    "############################\n",
    "# (D) DeepSORT\n",
    "############################\n",
    "tracker = DeepSort(\n",
    "    max_age=30,\n",
    "    n_init=3,\n",
    "    nms_max_overlap=1.0,\n",
    "    embedder='mobilenet',\n",
    "    half=True,\n",
    "    embedder_gpu=True\n",
    ")\n",
    "\n",
    "############################\n",
    "# (E) 메인 루프\n",
    "############################\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"카메라를 열 수 없습니다.\")\n",
    "    exit()\n",
    "\n",
    "dangerous_ids = set()\n",
    "track_me_status = {}\n",
    "track_arcface_count= {}\n",
    "MAX_ARCFACE_FRAMES= 20\n",
    "sim = 0\n",
    "\n",
    "window_name = \"DeepSORT + YOLO(SEG) + MobileFaceNet + Pose\"\n",
    "cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow(window_name, 960,720)\n",
    "\n",
    "prev_time = time.time()\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"프레임 읽기 실패!\")\n",
    "        break\n",
    "\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = model(rgb_frame, conf=0.5)\n",
    "    results_seg = model_seg(rgb_frame, conf=0.5)\n",
    "\n",
    "    # YOLO detection\n",
    "    det= results[0]\n",
    "    boxes2 = det.boxes\n",
    "    masks2 = results_seg[0].masks\n",
    "\n",
    "    person_detections= []\n",
    "    weapon_boxes= []\n",
    "\n",
    "    if boxes2 is not None:\n",
    "        for i, box in enumerate(boxes2):\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            class_id = int(box.cls[0])\n",
    "            conf = float(box.conf[0])\n",
    "\n",
    "            cv2.rectangle(frame, (x1,y1), (x2,y2), (0,255,0),2)\n",
    "            label = f\"{model.names[class_id]}: {conf:.2f}\"\n",
    "            cv2.putText(frame, label,(x1,y1-10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,0.5,(255,0,0),2)\n",
    "\n",
    "            # 세그 윤곽선(사람만)\n",
    "            if masks2 is not None and class_id==0:\n",
    "                if i < len(masks2.data):\n",
    "                    single_mask= masks2.data[i].cpu().numpy()\n",
    "                    mask_bin= (single_mask>0.5).astype(np.uint8)\n",
    "                    contours,_= cv2.findContours(mask_bin, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                    cv2.drawContours(frame, contours, -1, (0,255,255), 2)\n",
    "\n",
    "            # DeepSORT\n",
    "            if class_id==0:\n",
    "                w= x2 - x1\n",
    "                h= y2 - y1\n",
    "                person_detections.append(((x1,y1,w,h), conf,0))\n",
    "            elif class_id in [1,2]:\n",
    "                weapon_boxes.append((x1,y1,x2,y2))\n",
    "\n",
    "    # DeepSORT update\n",
    "    tracks= tracker.update_tracks(person_detections, frame=rgb_frame)\n",
    "    tracked_boxes=[]\n",
    "    for t in tracks:\n",
    "        if not t.is_confirmed() or t.time_since_update>1:\n",
    "            continue\n",
    "        tid= t.track_id\n",
    "        l,t_,r,b_ = map(int,t.to_ltrb())\n",
    "        tracked_boxes.append((tid,l,t_,r,b_))\n",
    "        cv2.putText(frame,f\"ID:{tid}\", (l-10,t_-10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,0.6,(0,255,255),2)\n",
    "\n",
    "    # MobileFaceNet 로직\n",
    "    time1 = time.time()\n",
    "    max_arcface_frames=10 # id 별로 초기 10프레임만 얼굴 인식\n",
    "    \n",
    "    for (tid, px1, py1, px2, py2) in tracked_boxes:\n",
    "        if tid not in track_me_status:\n",
    "            track_me_status[tid]= False\n",
    "        if tid not in track_arcface_count:\n",
    "            track_arcface_count[tid]=0\n",
    "\n",
    "        if track_arcface_count[tid]<max_arcface_frames:\n",
    "            print(f\"Running MobileFacenet for ID {tid} (Frame {track_arcface_count[tid]+1}/{MAX_ARCFACE_FRAMES})\")\n",
    "            track_arcface_count[tid]+=1\n",
    "\n",
    "            \n",
    "            # MobileFaceNet 임베딩 추출\n",
    "            PAD=10\n",
    "            sub_face= frame[max(0,py1-PAD): py2+PAD, max(0,px1-PAD): px2+PAD]\n",
    "            if sub_face.size==0:\n",
    "                continue\n",
    "\n",
    "            emb_image = get_mobileface_embedding(sub_face)\n",
    "            if emb_image is not None:\n",
    "                same_person, sim = is_my_face(emb_image, my_face_embedding, threshold=0.4)\n",
    "                if same_person:\n",
    "                    track_me_status[tid]=True\n",
    "                    if tid in dangerous_ids:\n",
    "                        dangerous_ids.remove(tid)\n",
    "\n",
    "        # 시각화\n",
    "        if track_me_status[tid]:\n",
    "            text_arc= f\"          Me(sim={sim:.2f})\"\n",
    "            color=(0,255,0)\n",
    "        else:\n",
    "            text_arc= \"           NotMe(sim={sim:.2f})\"\n",
    "            color=(0,0,255)\n",
    "        cv2.putText(frame,text_arc,(px1, py1-10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,0.6,color,2)\n",
    "    time2 = time.time()\n",
    "    print(\"MobileFacenet running time: \", time2-time1)\n",
    "\n",
    "    # 무기 교차 & NotMe => dangerous\n",
    "    for (tid, px1, py1, px2, py2) in tracked_boxes:\n",
    "        if not track_me_status[tid]:\n",
    "            pbox= (px1, py1, px2, py2)\n",
    "            for wb in weapon_boxes:\n",
    "                if boxes_overlap(pbox, wb):\n",
    "                    dangerous_ids.add(tid)\n",
    "                    break\n",
    "\n",
    "    # Dangerous => Mediapipe pose\n",
    "    for (tid, px1, py1, px2, py2) in tracked_boxes:\n",
    "        if tid in dangerous_ids:\n",
    "            sub= frame[py1:py2, px1:px2]\n",
    "            if sub.size==0:\n",
    "                continue\n",
    "            c_rgb= cv2.cvtColor(sub, cv2.COLOR_BGR2RGB)\n",
    "            pose_result= pose_danger.process(c_rgb)\n",
    "            if pose_result.pose_landmarks:\n",
    "                lms= pose_result.pose_landmarks.landmark\n",
    "                sub_w= px2 - px1\n",
    "                sub_h= py2 - py1\n",
    "\n",
    "                left_shoulder_y= lms[LEFT_SHOULDER].y\n",
    "                right_shoulder_y= lms[RIGHT_SHOULDER].y\n",
    "                left_wrist_y= lms[LEFT_WRIST].y\n",
    "                right_wrist_y= lms[RIGHT_WRIST].y\n",
    "\n",
    "                la_up= (left_wrist_y< (left_shoulder_y-0.05))\n",
    "                ra_up= (right_wrist_y<(right_shoulder_y-0.05))\n",
    "                if la_up and ra_up:\n",
    "                    a_text= \"both arms up\"\n",
    "                elif la_up:\n",
    "                    a_text= \"left arm up\"\n",
    "                elif ra_up:\n",
    "                    a_text= \"right arm up\"\n",
    "                else:\n",
    "                    a_text= \"do nothing\"\n",
    "\n",
    "                for lm in lms:\n",
    "                    cx= px1+int(lm.x*sub_w)\n",
    "                    cy= py1+int(lm.y*sub_h)\n",
    "                    cv2.circle(frame,(cx,cy),3,(0,255,255),-1)\n",
    "                cv2.putText(frame,f\"Dangerous person: {a_text}\",\n",
    "                            (px1,py1+20),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX,0.7,(0,0,255),2)\n",
    "\n",
    "    # FPS 표시\n",
    "    now= time.time()\n",
    "    fps= 1.0/(now - prev_time)\n",
    "    prev_time= now\n",
    "    cv2.putText(frame,f\"FPS:{fps:.2f}\",(10,30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),2)\n",
    "\n",
    "    cv2.imshow(window_name, frame)\n",
    "    if cv2.waitKey(1)&0xFF==ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version: 3.8.5 (default, Sep  3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]\n",
      "torch version: 1.12.1+cu116\n",
      "CUDA Version: 11.6\n",
      "CUDA Available: False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "\n",
    "print(\"python version:\", sys.version)\n",
    "print(\"torch version:\", torch.__version__)\n",
    "print(\"CUDA Version:\", torch.version.cuda)\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install torch==1.12.1+cu116 torchvision==0.13.1+cu116 torchaudio==0.12.1 --extra-index-url https://download.pytorch.org/whl/cu116"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용 가능한 GPU 수: 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"사용 가능한 GPU 수:\", torch.cuda.device_count())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU 이름:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
