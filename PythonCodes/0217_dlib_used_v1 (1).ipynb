{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d2e44ad-6944-4d12-88db-e89def74a497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 personnnn, 123.0ms\n",
      "Speed: 0.0ms preprocess, 123.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 448x640 1 person, 179.6ms\n",
      "Speed: 3.8ms preprocess, 179.6ms inference, 4.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 480x640 (no detections), 102.2ms\n",
      "Speed: 3.7ms preprocess, 102.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 personnnn, 1 knifeeeee, 95.9ms\n",
      "Speed: 2.0ms preprocess, 95.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 416x640 2 persons, 131.8ms\n",
      "Speed: 0.0ms preprocess, 131.8ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "0: 480x640 (no detections), 89.1ms\n",
      "Speed: 0.0ms preprocess, 89.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 personnnn, 87.3ms\n",
      "Speed: 0.0ms preprocess, 87.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 416x640 2 persons, 90.7ms\n",
      "Speed: 2.0ms preprocess, 90.7ms inference, 8.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "0: 480x640 (no detections), 72.9ms\n",
      "Speed: 8.0ms preprocess, 72.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 personnnn, 104.0ms\n",
      "Speed: 0.0ms preprocess, 104.0ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 416x640 2 persons, 100.3ms\n",
      "Speed: 3.0ms preprocess, 100.3ms inference, 2.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "0: 480x640 (no detections), 79.7ms\n",
      "Speed: 3.2ms preprocess, 79.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 personnnn, 91.7ms\n",
      "Speed: 0.0ms preprocess, 91.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 416x640 3 persons, 91.0ms\n",
      "Speed: 2.0ms preprocess, 91.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "0: 480x640 (no detections), 88.1ms\n",
      "Speed: 0.0ms preprocess, 88.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 personnnn, 94.4ms\n",
      "Speed: 3.2ms preprocess, 94.4ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 448x640 2 persons, 103.8ms\n",
      "Speed: 3.0ms preprocess, 103.8ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 480x640 (no detections), 85.8ms\n",
      "Speed: 1.8ms preprocess, 85.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 personnnn, 88.9ms\n",
      "Speed: 0.0ms preprocess, 88.9ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 448x640 2 persons, 104.4ms\n",
      "Speed: 2.7ms preprocess, 104.4ms inference, 2.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 480x640 (no detections), 84.6ms\n",
      "Speed: 3.5ms preprocess, 84.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 personnnn, 90.8ms\n",
      "Speed: 0.0ms preprocess, 90.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 130.4ms\n",
      "Speed: 0.0ms preprocess, 130.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 76.8ms\n",
      "Speed: 1.6ms preprocess, 76.8ms inference, 8.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 personnnn, 90.1ms\n",
      "Speed: 0.0ms preprocess, 90.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 102.5ms\n",
      "Speed: 3.8ms preprocess, 102.5ms inference, 8.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 73.3ms\n",
      "Speed: 2.7ms preprocess, 73.3ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 personnnn, 89.0ms\n",
      "Speed: 0.0ms preprocess, 89.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 512x640 1 person, 1 cell phone, 142.4ms\n",
      "Speed: 3.7ms preprocess, 142.4ms inference, 10.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 480x640 (no detections), 85.6ms\n",
      "Speed: 1.5ms preprocess, 85.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 personnnn, 87.9ms\n",
      "Speed: 0.0ms preprocess, 87.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 544x640 1 person, 1 cell phone, 154.5ms\n",
      "Speed: 4.0ms preprocess, 154.5ms inference, 0.0ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "0: 480x640 (no detections), 78.6ms\n",
      "Speed: 0.7ms preprocess, 78.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 personnnn, 83.0ms\n",
      "Speed: 2.0ms preprocess, 83.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 576x640 1 person, 161.0ms\n",
      "Speed: 10.7ms preprocess, 161.0ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 480x640 (no detections), 208.0ms\n",
      "Speed: 3.1ms preprocess, 208.0ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 personnnn, 92.7ms\n",
      "Speed: 2.0ms preprocess, 92.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 608x640 1 person, 165.1ms\n",
      "Speed: 4.0ms preprocess, 165.1ms inference, 2.0ms postprocess per image at shape (1, 3, 608, 640)\n",
      "\n",
      "0: 480x640 (no detections), 81.5ms\n",
      "Speed: 2.7ms preprocess, 81.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 personnnn, 81.9ms\n",
      "Speed: 2.0ms preprocess, 81.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 576x640 1 person, 1 chair, 127.3ms\n",
      "Speed: 5.7ms preprocess, 127.3ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 480x640 (no detections), 77.6ms\n",
      "Speed: 0.9ms preprocess, 77.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 personnnn, 88.1ms\n",
      "Speed: 0.0ms preprocess, 88.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 544x640 1 person, 124.4ms\n",
      "Speed: 3.2ms preprocess, 124.4ms inference, 0.0ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "0: 480x640 (no detections), 78.6ms\n",
      "Speed: 2.1ms preprocess, 78.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 personnnn, 80.9ms\n",
      "Speed: 2.0ms preprocess, 80.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 512x640 1 person, 108.7ms\n",
      "Speed: 3.1ms preprocess, 108.7ms inference, 8.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 480x640 (no detections), 76.4ms\n",
      "Speed: 2.4ms preprocess, 76.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 personnnn, 90.2ms\n",
      "Speed: 0.0ms preprocess, 90.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 512x640 1 person, 113.3ms\n",
      "Speed: 3.1ms preprocess, 113.3ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 480x640 (no detections), 86.4ms\n",
      "Speed: 2.6ms preprocess, 86.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 personnnns, 90.2ms\n",
      "Speed: 0.0ms preprocess, 90.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 512x640 1 person, 112.1ms\n",
      "Speed: 3.0ms preprocess, 112.1ms inference, 8.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 640x256 (no detections), 97.2ms\n",
      "Speed: 2.4ms preprocess, 97.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 256)\n",
      "\n",
      "0: 480x640 (no detections), 90.5ms\n",
      "Speed: 2.3ms preprocess, 90.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 personnnns, 91.1ms\n",
      "Speed: 0.0ms preprocess, 91.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 512x640 1 person, 121.1ms\n",
      "Speed: 0.0ms preprocess, 121.1ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 640x256 (no detections), 76.7ms\n",
      "Speed: 1.7ms preprocess, 76.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 256)\n",
      "\n",
      "0: 480x640 (no detections), 86.4ms\n",
      "Speed: 4.0ms preprocess, 86.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 personnnns, 91.7ms\n",
      "Speed: 2.0ms preprocess, 91.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 111.9ms\n",
      "Speed: 2.9ms preprocess, 111.9ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 640x320 1 person, 124.2ms\n",
      "Speed: 1.5ms preprocess, 124.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "\n",
      "0: 640x448 1 person, 169.9ms\n",
      "Speed: 3.0ms preprocess, 169.9ms inference, 10.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 480x640 (no detections), 113.6ms\n",
      "Speed: 2.0ms preprocess, 113.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 personnnns, 99.9ms\n",
      "Speed: 0.0ms preprocess, 99.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 bottle, 1 chair, 150.4ms\n",
      "Speed: 3.0ms preprocess, 150.4ms inference, 10.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 640x320 1 person, 123.7ms\n",
      "Speed: 4.0ms preprocess, 123.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "\n",
      "0: 480x640 (no detections), 89.2ms\n",
      "Speed: 2.0ms preprocess, 89.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 personnnns, 112.9ms\n",
      "Speed: 2.0ms preprocess, 112.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.2ms\n",
      "Speed: 3.2ms preprocess, 143.2ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 640x320 1 person, 88.8ms\n",
      "Speed: 2.0ms preprocess, 88.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "\n",
      "0: 480x640 (no detections), 80.4ms\n",
      "Speed: 3.0ms preprocess, 80.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 personnnns, 80.4ms\n",
      "Speed: 3.0ms preprocess, 80.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 512x640 1 person, 1 chair, 111.2ms\n",
      "Speed: 0.0ms preprocess, 111.2ms inference, 10.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 640x288 1 person, 92.8ms\n",
      "Speed: 1.5ms preprocess, 92.8ms inference, 8.0ms postprocess per image at shape (1, 3, 640, 288)\n",
      "\n",
      "0: 480x640 (no detections), 88.5ms\n",
      "Speed: 3.0ms preprocess, 88.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 personnnn, 88.0ms\n",
      "Speed: 0.0ms preprocess, 88.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 576x640 1 person, 122.7ms\n",
      "Speed: 3.2ms preprocess, 122.7ms inference, 10.1ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 480x640 (no detections), 86.3ms\n",
      "Speed: 2.3ms preprocess, 86.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 personnnn, 86.4ms\n",
      "Speed: 4.3ms preprocess, 86.4ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 640x640 1 person, 174.0ms\n",
      "Speed: 4.5ms preprocess, 174.0ms inference, 8.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 (no detections), 81.4ms\n",
      "Speed: 2.0ms preprocess, 81.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 personnnn, 83.7ms\n",
      "Speed: 2.0ms preprocess, 83.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 640x640 1 person, 137.5ms\n",
      "Speed: 3.4ms preprocess, 137.5ms inference, 8.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 (no detections), 84.3ms\n",
      "Speed: 3.0ms preprocess, 84.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 personnnn, 89.5ms\n",
      "Speed: 0.0ms preprocess, 89.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 640x640 1 person, 139.7ms\n",
      "Speed: 4.1ms preprocess, 139.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 (no detections), 81.6ms\n",
      "Speed: 2.6ms preprocess, 81.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 personnnn, 90.3ms\n",
      "Speed: 3.0ms preprocess, 90.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 640x640 1 person, 135.2ms\n",
      "Speed: 4.6ms preprocess, 135.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 (no detections), 86.1ms\n",
      "Speed: 2.4ms preprocess, 86.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 personnnn, 89.5ms\n",
      "Speed: 0.0ms preprocess, 89.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 544x640 1 person, 119.9ms\n",
      "Speed: 3.0ms preprocess, 119.9ms inference, 10.1ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "0: 480x640 (no detections), 91.7ms\n",
      "Speed: 2.0ms preprocess, 91.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 personnnn, 82.3ms\n",
      "Speed: 2.0ms preprocess, 82.3ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 544x640 2 persons, 125.7ms\n",
      "Speed: 3.5ms preprocess, 125.7ms inference, 0.0ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "0: 480x640 (no detections), 89.5ms\n",
      "Speed: 1.9ms preprocess, 89.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 personnnn, 88.1ms\n",
      "Speed: 0.0ms preprocess, 88.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 512x640 2 persons, 1 chair, 119.1ms\n",
      "Speed: 2.9ms preprocess, 119.1ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 480x640 (no detections), 80.2ms\n",
      "Speed: 1.5ms preprocess, 80.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 personnnn, 89.1ms\n",
      "Speed: 0.0ms preprocess, 89.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 111.1ms\n",
      "Speed: 10.3ms preprocess, 111.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 90.2ms\n",
      "Speed: 2.0ms preprocess, 90.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import dlib\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "############################\n",
    "# 1) Dlib 모델 초기화\n",
    "############################\n",
    "PREDICTOR_PATH = \"C:/face/shape_predictor_68_face_landmarks.dat\"\n",
    "FACE_REC_MODEL_PATH = \"C:/face/dlib_face_recognition_resnet_model_v1.dat\"\n",
    "MYFACE_DIR = \"C:/myface\"\n",
    "\n",
    "# Dlib 모델 로드\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(PREDICTOR_PATH)\n",
    "face_rec_model = dlib.face_recognition_model_v1(FACE_REC_MODEL_PATH)\n",
    "\n",
    "# 저장된 얼굴 임베딩 로드\n",
    "if os.path.exists(\"my_face_embedding.npy\"):\n",
    "    my_face_embedding = np.load(\"my_face_embedding.npy\")\n",
    "else:\n",
    "    raise FileNotFoundError(\"my_face_embedding.npy 파일이 존재하지 않습니다. 먼저 얼굴을 학습시키세요!\")\n",
    "\n",
    "############################\n",
    "# 2) 얼굴 학습 (등록) 함수\n",
    "############################\n",
    "def get_face_embedding(image):\n",
    "    \"\"\" 얼굴 임베딩 추출 (Dlib) \"\"\"\n",
    "    faces = detector(image)\n",
    "    if len(faces) > 0:\n",
    "        shape = predictor(image, faces[0])\n",
    "        face_descriptor = face_rec_model.compute_face_descriptor(image, shape)\n",
    "        return np.array(face_descriptor)\n",
    "    return None\n",
    "\n",
    "def generate_average_embedding(folder_path):\n",
    "    \"\"\" 등록된 얼굴 사진으로 평균 임베딩 생성 \"\"\"\n",
    "    embeddings = []\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            img_path = os.path.join(folder_path, file)\n",
    "            image = cv2.imread(img_path)\n",
    "            if image is None:\n",
    "                print(f\"이미지 로드 실패: {img_path}\")\n",
    "                continue\n",
    "\n",
    "            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            embedding = get_face_embedding(image_rgb)\n",
    "            if embedding is not None:\n",
    "                embeddings.append(embedding)\n",
    "            else:\n",
    "                print(f\"얼굴 검출 실패: {img_path}\")\n",
    "\n",
    "    if len(embeddings) == 0:\n",
    "        raise ValueError(\"임베딩을 하나도 생성하지 못했습니다.\")\n",
    "    \n",
    "    avg_embedding = np.mean(embeddings, axis=0)\n",
    "    np.save(\"my_face_embedding.npy\", avg_embedding)\n",
    "    print(\"✅ 내 얼굴 평균 임베딩 저장 완료!\")\n",
    "\n",
    "############################\n",
    "# 3) 얼굴 임베딩 비교 함수\n",
    "############################\n",
    "def is_my_face(face_embedding, my_face_embedding, threshold=0.6):\n",
    "    \"\"\" Dlib 임베딩을 사용하여 유사도 비교 \"\"\"\n",
    "    if face_embedding is None:\n",
    "        return False, 0.0\n",
    "    similarity = 1 - np.linalg.norm(my_face_embedding - face_embedding)  # 거리 기반 유사도\n",
    "    return similarity > threshold, similarity\n",
    "\n",
    "############################\n",
    "# 4) YOLO + DeepSORT 초기화\n",
    "############################\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# YOLO 모델 로드\n",
    "detection_model = YOLO(\"C:/epoch180.pt\").to(device)\n",
    "segmentation_model = YOLO(\"yolov8n-seg.pt\").to(device)\n",
    "face_model = YOLO(\"C:/face1.pt\").to(device)\n",
    "\n",
    "# DeepSORT 트래커 초기화\n",
    "tracker = DeepSort(max_age=30, n_init=3, embedder='mobilenet', half=True, embedder_gpu=True)\n",
    "\n",
    "############################\n",
    "# 5) 얼굴 탐지 및 Segmentation\n",
    "############################\n",
    "def detect_faces(image):\n",
    "    \"\"\" YOLO를 사용하여 얼굴 탐지 \"\"\"\n",
    "    face_bboxes = []\n",
    "    face_results = face_model(image)\n",
    "    for box in face_results[0].boxes:\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "        conf = float(box.conf)\n",
    "        face_bboxes.append((x1, y1, x2, y2, conf))\n",
    "    return face_bboxes\n",
    "\n",
    "def apply_segmentation(image, bboxes):\n",
    "    \"\"\" Segmentation 모델을 사용하여 사람 영역 내 마스크 적용 \"\"\"\n",
    "    for (x1, y1, x2, y2) in bboxes:\n",
    "        person_crop = image[y1:y2, x1:x2]\n",
    "        if person_crop.size == 0:\n",
    "            continue\n",
    "        segmentation_results = segmentation_model(person_crop)\n",
    "        if segmentation_results[0].masks is not None:\n",
    "            for mask in segmentation_results[0].masks.data:\n",
    "                mask = mask.cpu().numpy()\n",
    "                mask_resized = cv2.resize(mask, (x2 - x1, y2 - y1))\n",
    "                mask_binary = (mask_resized > 0.5).astype(np.uint8)\n",
    "                color_mask = np.zeros_like(person_crop, dtype=np.uint8)\n",
    "                color_mask[:, :, 1] = mask_binary * 255\n",
    "                person_crop = cv2.addWeighted(person_crop, 1, color_mask, 0.5, 0)\n",
    "                image[y1:y2, x1:x2] = person_crop\n",
    "    return image\n",
    "\n",
    "############################\n",
    "# 6) 실시간 웹캠 실행\n",
    "############################\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"웹캠을 열 수 없습니다.\")\n",
    "    exit()\n",
    "\n",
    "window_name = \"YOLOv8 + DeepSORT + Segmentation + Dlib Face Recognition\"\n",
    "cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow(window_name, 960, 720)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"프레임 읽기 실패!\")\n",
    "        break\n",
    "\n",
    "    # YOLO 사람 탐지 실행\n",
    "    detection_results = detection_model(frame)\n",
    "    bboxes = []\n",
    "    detections = []\n",
    "\n",
    "    for box in detection_results[0].boxes:\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "        class_id = int(box.cls)\n",
    "        conf = float(box.conf)\n",
    "\n",
    "        # 사람(클래스 ID 0)만 탐지\n",
    "        if class_id == 0:\n",
    "            bboxes.append((x1, y1, x2, y2))\n",
    "            detections.append(((x1, y1, x2 - x1, y2 - y1), conf, 0))\n",
    "\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"Person {conf:.2f}\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "    # Segmentation 적용\n",
    "    frame = apply_segmentation(frame, bboxes)\n",
    "\n",
    "    # 얼굴 탐지 및 인식\n",
    "    face_bboxes = detect_faces(frame)\n",
    "    for x1, y1, x2, y2, conf in face_bboxes:\n",
    "        face_crop = frame[y1:y2, x1:x2]\n",
    "        face_embedding = get_face_embedding(face_crop)\n",
    "\n",
    "        if face_embedding is not None:\n",
    "            is_me, similarity = is_my_face(face_embedding, my_face_embedding)\n",
    "            color = (0, 255, 0) if is_me else (0, 0, 255)\n",
    "            cv2.putText(frame, f\"Me: {similarity:.2f}\" if is_me else \"Not Me\", (x1, y1 + 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "\n",
    "    cv2.imshow(window_name, frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc30cd1c-4cd1-4783-81a0-211e7af77ede",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
