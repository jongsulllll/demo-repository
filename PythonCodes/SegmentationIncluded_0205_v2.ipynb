{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 사람 + 총 + 칼 인식    \n",
    "2. Arcface를 모든 사람에 대해 적용(Me, NotME)  \n",
    "3. NotMe이면서 사람과 총 혹은 칼의 bounding box가 겹치는 경우에는 위험인으로 분류 -> 한 번 위험인으로 분류된 사람의 ID는 dangerous_ids로 관리됨 -> dangerous_ids 중 하나에 해당하는 사람은 위에 \"Dangerous person\"이라고 뜸\n",
    "4. pose estimation을 dangerous person에 대해 적용(왼팔들기, 오른팔들기, 양팔들기)  \n",
    "5. 출력화면 사이즈를 키움  \n",
    "6. 버그수정: 초기에 무기와 교차하여 dangerous_ids에 들어갔더라도, ArcFace로 내 얼굴임이 확인되면(=나 자신이 무기를 소지한 상황) 그 사람을 위험 인물에서 제외  \n",
    "7. Kobukki robot이 dangerous_ids 내에 있는 사람을 쫓아가도록 하면 될 듯  \n",
    "\n",
    "+ Yolo segmentation까지 추가\n",
    "+ 현재 YOLO를 사용하고 있으므로, YOLOv8-seg 모델을 사용하는 것이 가장 간단함.\n",
    "\n",
    "총이나 칼을 들고 있는 손의 정확한 위치를 파악해서 정밀하게 무기를 감지할 수 있음\n",
    "옷 색깔이나 패턴을 인식해서 사람 구별 정확도 높아짐\n",
    "제스처 구분 정확도 높아짐 \n",
    "YOLOv8-seg 모델 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py:69: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\user/.insightface\\models\\buffalo_l\\1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\user/.insightface\\models\\buffalo_l\\2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\user/.insightface\\models\\buffalo_l\\det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\user/.insightface\\models\\buffalo_l\\genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\user/.insightface\\models\\buffalo_l\\w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\insightface\\utils\\transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "내 얼굴 평균 임베딩 생성 완료.\n"
     ]
    }
   ],
   "source": [
    "#1. 얼굴 학습시키는 부분\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from insightface.app import FaceAnalysis\n",
    "\n",
    "def initialize_arcface():\n",
    "    app = FaceAnalysis(name=\"buffalo_l\")  # ArcFace 모델 (buffalo_l은 기본 권장)\n",
    "    app.prepare(ctx_id=-1, det_size=(640, 640))  # GPU: ctx_id=0, CPU: -1\n",
    "    return app\n",
    "\n",
    "def get_face_embedding(app, image_bgr):\n",
    "    # ArcFace의 app.get()은 BGR 형식으로 이미지를 받기도 합니다.\n",
    "    # 만약 RGB가 필요하면 cvtColor로 변환하세요.\n",
    "    faces = app.get(image_bgr)\n",
    "    if len(faces) > 0:\n",
    "        return faces[0].embedding  # 첫 번째 얼굴의 임베딩\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def generate_average_embedding(app, folder_path):\n",
    "    embeddings = []\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            img_path = os.path.join(folder_path, file)\n",
    "            image = cv2.imread(img_path)\n",
    "            if image is None:\n",
    "                print(f\"이미지 로드 실패: {img_path}\")\n",
    "                continue\n",
    "            \n",
    "            embedding = get_face_embedding(app, image)\n",
    "            if embedding is not None:\n",
    "                embeddings.append(embedding)\n",
    "            else:\n",
    "                print(f\"얼굴 검출 실패: {img_path}\")\n",
    "    \n",
    "    if len(embeddings) == 0:\n",
    "        raise ValueError(\"임베딩을 하나도 생성하지 못했습니다.\")\n",
    "    \n",
    "    avg_embedding = np.mean(embeddings, axis=0)\n",
    "    return avg_embedding\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app = initialize_arcface()\n",
    "    # 내 얼굴 사진 폴더\n",
    "    my_face_folder = \"C:/myface\"  \n",
    "    my_face_embedding = generate_average_embedding(app, my_face_folder)\n",
    "    np.save(\"my_face_embedding.npy\", my_face_embedding)  # 필요 시 저장\n",
    "    print(\"내 얼굴 평균 임베딩 생성 완료.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py:69: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\user/.insightface\\models\\buffalo_l\\1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\user/.insightface\\models\\buffalo_l\\2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\user/.insightface\\models\\buffalo_l\\det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\user/.insightface\\models\\buffalo_l\\genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\user/.insightface\\models\\buffalo_l\\w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (640, 640)\n",
      "\n",
      "0: 480x640 1 person, 154.4ms\n",
      "Speed: 15.6ms preprocess, 154.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 122.1ms\n",
      "Speed: 2.5ms preprocess, 122.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 114.8ms\n",
      "Speed: 3.0ms preprocess, 114.8ms inference, 7.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 145.6ms\n",
      "Speed: 0.0ms preprocess, 145.6ms inference, 6.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 145.4ms\n",
      "Speed: 3.9ms preprocess, 145.4ms inference, 6.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 162.5ms\n",
      "Speed: 3.0ms preprocess, 162.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 121.0ms\n",
      "Speed: 1.0ms preprocess, 121.0ms inference, 4.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 120.7ms\n",
      "Speed: 3.0ms preprocess, 120.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 116.1ms\n",
      "Speed: 0.0ms preprocess, 116.1ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 110.8ms\n",
      "Speed: 3.0ms preprocess, 110.8ms inference, 3.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.1ms\n",
      "Speed: 0.0ms preprocess, 142.1ms inference, 3.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 149.5ms\n",
      "Speed: 1.0ms preprocess, 149.5ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 112.3ms\n",
      "Speed: 3.0ms preprocess, 112.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 122.2ms\n",
      "Speed: 0.0ms preprocess, 122.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 115.3ms\n",
      "Speed: 2.0ms preprocess, 115.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 106.6ms\n",
      "Speed: 3.0ms preprocess, 106.6ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 111.1ms\n",
      "Speed: 2.0ms preprocess, 111.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 148.9ms\n",
      "Speed: 2.1ms preprocess, 148.9ms inference, 4.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 131.9ms\n",
      "Speed: 3.0ms preprocess, 131.9ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 113.4ms\n",
      "Speed: 3.9ms preprocess, 113.4ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.6ms\n",
      "Speed: 3.5ms preprocess, 144.6ms inference, 5.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 112.5ms\n",
      "Speed: 2.0ms preprocess, 112.5ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 111.2ms\n",
      "Speed: 3.0ms preprocess, 111.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.2ms\n",
      "Speed: 4.2ms preprocess, 143.2ms inference, 7.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.2ms\n",
      "Speed: 4.0ms preprocess, 142.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 114.3ms\n",
      "Speed: 4.3ms preprocess, 114.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 117.3ms\n",
      "Speed: 0.0ms preprocess, 117.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 117.7ms\n",
      "Speed: 0.0ms preprocess, 117.7ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 111.0ms\n",
      "Speed: 2.0ms preprocess, 111.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 126.0ms\n",
      "Speed: 0.0ms preprocess, 126.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 145.0ms\n",
      "Speed: 3.2ms preprocess, 145.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 114.7ms\n",
      "Speed: 2.9ms preprocess, 114.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 128.7ms\n",
      "Speed: 34.1ms preprocess, 128.7ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 117.7ms\n",
      "Speed: 0.0ms preprocess, 117.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 113.0ms\n",
      "Speed: 1.5ms preprocess, 113.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 122.4ms\n",
      "Speed: 0.0ms preprocess, 122.4ms inference, 4.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 149.3ms\n",
      "Speed: 3.8ms preprocess, 149.3ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 113.5ms\n",
      "Speed: 2.1ms preprocess, 113.5ms inference, 8.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 115.0ms\n",
      "Speed: 3.0ms preprocess, 115.0ms inference, 7.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 117.2ms\n",
      "Speed: 0.0ms preprocess, 117.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 112.1ms\n",
      "Speed: 4.1ms preprocess, 112.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 112.4ms\n",
      "Speed: 2.5ms preprocess, 112.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 145.0ms\n",
      "Speed: 1.5ms preprocess, 145.0ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.8ms\n",
      "Speed: 3.3ms preprocess, 143.8ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 116.7ms\n",
      "Speed: 3.4ms preprocess, 116.7ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 120.5ms\n",
      "Speed: 0.0ms preprocess, 120.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 114.1ms\n",
      "Speed: 3.7ms preprocess, 114.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 112.4ms\n",
      "Speed: 2.0ms preprocess, 112.4ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 123.7ms\n",
      "Speed: 3.0ms preprocess, 123.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 150.4ms\n",
      "Speed: 2.3ms preprocess, 150.4ms inference, 5.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 117.3ms\n",
      "Speed: 3.8ms preprocess, 117.3ms inference, 5.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 112.5ms\n",
      "Speed: 0.0ms preprocess, 112.5ms inference, 10.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 116.6ms\n",
      "Speed: 4.7ms preprocess, 116.6ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 127.0ms\n",
      "Speed: 3.0ms preprocess, 127.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 139.5ms\n",
      "Speed: 1.6ms preprocess, 139.5ms inference, 3.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 164.7ms\n",
      "Speed: 2.5ms preprocess, 164.7ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 145.1ms\n",
      "Speed: 2.7ms preprocess, 145.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 134.5ms\n",
      "Speed: 3.7ms preprocess, 134.5ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 122.4ms\n",
      "Speed: 3.7ms preprocess, 122.4ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 135.2ms\n",
      "Speed: 3.8ms preprocess, 135.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 137.1ms\n",
      "Speed: 3.1ms preprocess, 137.1ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 157.3ms\n",
      "Speed: 0.0ms preprocess, 157.3ms inference, 3.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 129.1ms\n",
      "Speed: 3.4ms preprocess, 129.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 115.4ms\n",
      "Speed: 4.5ms preprocess, 115.4ms inference, 7.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 114.8ms\n",
      "Speed: 3.9ms preprocess, 114.8ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 113.9ms\n",
      "Speed: 3.6ms preprocess, 113.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 108.9ms\n",
      "Speed: 2.6ms preprocess, 108.9ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 142.9ms\n",
      "Speed: 2.9ms preprocess, 142.9ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.6ms\n",
      "Speed: 1.8ms preprocess, 144.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 117.4ms\n",
      "Speed: 2.2ms preprocess, 117.4ms inference, 6.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 toothbrush, 113.1ms\n",
      "Speed: 3.2ms preprocess, 113.1ms inference, 9.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 toothbrush, 120.9ms\n",
      "Speed: 2.4ms preprocess, 120.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 105.7ms\n",
      "Speed: 2.6ms preprocess, 105.7ms inference, 10.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 126.8ms\n",
      "Speed: 3.4ms preprocess, 126.8ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 149.5ms\n",
      "Speed: 2.6ms preprocess, 149.5ms inference, 5.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 cell phone, 120.6ms\n",
      "Speed: 3.2ms preprocess, 120.6ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 cell phone, 109.3ms\n",
      "Speed: 3.6ms preprocess, 109.3ms inference, 9.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 cell phone, 116.2ms\n",
      "Speed: 3.1ms preprocess, 116.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 cell phone, 126.2ms\n",
      "Speed: 2.6ms preprocess, 126.2ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 cell phone, 108.6ms\n",
      "Speed: 3.6ms preprocess, 108.6ms inference, 12.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 cell phone, 112.9ms\n",
      "Speed: 3.1ms preprocess, 112.9ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 cell phone, 118.0ms\n",
      "Speed: 3.0ms preprocess, 118.0ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 cell phone, 114.5ms\n",
      "Speed: 3.4ms preprocess, 114.5ms inference, 6.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 cell phone, 124.6ms\n",
      "Speed: 2.0ms preprocess, 124.6ms inference, 7.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 cell phone, 125.6ms\n",
      "Speed: 9.3ms preprocess, 125.6ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 cell phone, 176.5ms\n",
      "Speed: 58.3ms preprocess, 176.5ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 120.6ms\n",
      "Speed: 1.9ms preprocess, 120.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 118.2ms\n",
      "Speed: 3.7ms preprocess, 118.2ms inference, 7.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 118.0ms\n",
      "Speed: 1.0ms preprocess, 118.0ms inference, 5.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 116.3ms\n",
      "Speed: 2.6ms preprocess, 116.3ms inference, 4.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 115.4ms\n",
      "Speed: 3.1ms preprocess, 115.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 cell phone, 120.9ms\n",
      "Speed: 2.3ms preprocess, 120.9ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 cell phone, 112.9ms\n",
      "Speed: 3.7ms preprocess, 112.9ms inference, 6.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 laptop, 1 cell phone, 116.3ms\n",
      "Speed: 2.6ms preprocess, 116.3ms inference, 9.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 laptop, 1 cell phone, 116.1ms\n",
      "Speed: 2.6ms preprocess, 116.1ms inference, 5.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 113.5ms\n",
      "Speed: 1.7ms preprocess, 113.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 115.2ms\n",
      "Speed: 2.2ms preprocess, 115.2ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 111.9ms\n",
      "Speed: 2.9ms preprocess, 111.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 114.2ms\n",
      "Speed: 3.2ms preprocess, 114.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 118.7ms\n",
      "Speed: 2.4ms preprocess, 118.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 116.8ms\n",
      "Speed: 2.2ms preprocess, 116.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 117.9ms\n",
      "Speed: 2.8ms preprocess, 117.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 114.2ms\n",
      "Speed: 3.0ms preprocess, 114.2ms inference, 7.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 115.3ms\n",
      "Speed: 3.0ms preprocess, 115.3ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 111.9ms\n",
      "Speed: 3.1ms preprocess, 111.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 118.3ms\n",
      "Speed: 0.0ms preprocess, 118.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 121.7ms\n",
      "Speed: 3.8ms preprocess, 121.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 127.8ms\n",
      "Speed: 1.0ms preprocess, 127.8ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 132.3ms\n",
      "Speed: 3.0ms preprocess, 132.3ms inference, 8.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 125.4ms\n",
      "Speed: 3.1ms preprocess, 125.4ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 118.6ms\n",
      "Speed: 3.0ms preprocess, 118.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 119.4ms\n",
      "Speed: 0.0ms preprocess, 119.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 114.7ms\n",
      "Speed: 3.8ms preprocess, 114.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 130.9ms\n",
      "Speed: 3.3ms preprocess, 130.9ms inference, 7.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 129.6ms\n",
      "Speed: 6.0ms preprocess, 129.6ms inference, 7.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 135.3ms\n",
      "Speed: 2.0ms preprocess, 135.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 127.2ms\n",
      "Speed: 0.0ms preprocess, 127.2ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 128.7ms\n",
      "Speed: 0.0ms preprocess, 128.7ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 126.9ms\n",
      "Speed: 4.1ms preprocess, 126.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 122.3ms\n",
      "Speed: 2.0ms preprocess, 122.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 121.9ms\n",
      "Speed: 3.4ms preprocess, 121.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 153.0ms\n",
      "Speed: 54.8ms preprocess, 153.0ms inference, 4.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 131.0ms\n",
      "Speed: 0.0ms preprocess, 131.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 119.1ms\n",
      "Speed: 0.0ms preprocess, 119.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 117.1ms\n",
      "Speed: 0.0ms preprocess, 117.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 112.7ms\n",
      "Speed: 3.2ms preprocess, 112.7ms inference, 8.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 118.2ms\n",
      "Speed: 0.0ms preprocess, 118.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from ultralytics import YOLO\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from insightface.app import FaceAnalysis\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "\n",
    "############################\n",
    "# 1) 모델 및 함수 초기화\n",
    "############################\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# YOLO Segmentation 모델 로드\n",
    "segmentation_model = \"yolov8n-seg.pt\"  # 반드시 Segmentation 모델 사용\n",
    "model = YOLO(segmentation_model).to(device)\n",
    "\n",
    "# ArcFace\n",
    "arc_app = FaceAnalysis(name=\"buffalo_l\")\n",
    "arc_app.prepare(ctx_id=-1, det_size=(640, 640))\n",
    "my_face_embedding = np.load(\"my_face_embedding.npy\")\n",
    "\n",
    "# DeepSORT 초기화\n",
    "tracker = DeepSort(max_age=30, n_init=3, embedder='mobilenet', half=True, embedder_gpu=True)\n",
    "\n",
    "############################\n",
    "# 2) 실시간 웹캠 캡처\n",
    "############################\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"웹캠을 열 수 없습니다.\")\n",
    "    exit()\n",
    "\n",
    "prev_time = time.time()\n",
    "window_name = \"YOLOv8 Segmentation + DeepSORT Tracking\"\n",
    "cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow(window_name, 960, 720)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"프레임 읽기 실패!\")\n",
    "        break\n",
    "\n",
    "    # YOLO Segmentation 추론 실행\n",
    "    results = model(frame)\n",
    "\n",
    "    # 마스크를 적용할 빈 프레임 생성\n",
    "    mask_overlay = np.zeros_like(frame, dtype=np.uint8)\n",
    "\n",
    "    for result in results:\n",
    "        if result.masks is not None:\n",
    "            for mask, box in zip(result.masks.data, result.boxes):\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0])  # 바운딩 박스 좌표\n",
    "                class_id = int(box.cls)  # 객체 클래스 ID\n",
    "                conf = float(box.conf)  # 신뢰도 점수\n",
    "                class_name = model.names[class_id]  # 객체 이름\n",
    "                mask = mask.cpu().numpy()  # Segmentation 마스크 (0~1 값)\n",
    "\n",
    "                # 바운딩 박스 그리기\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                label = f\"{class_name}: {conf:.2f}\"\n",
    "                cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "\n",
    "                # 마스크 크기를 원본 프레임 크기에 맞추기\n",
    "                mask_resized = cv2.resize(mask, (frame.shape[1], frame.shape[0]))\n",
    "\n",
    "                # 사람이면 초록색, 무기면 빨간색 마스크 적용\n",
    "                if class_id == 0:  # person\n",
    "                    color = (0, 255, 0)  # 초록색\n",
    "                elif class_id in [1, 2]:  # gun or knife\n",
    "                    color = (0, 0, 255)  # 빨간색\n",
    "                else:\n",
    "                    continue  # 기타 객체는 무시\n",
    "\n",
    "                # 마스크 적용\n",
    "                mask_binary = (mask_resized > 0.5).astype(np.uint8)  # 이진화\n",
    "                color_mask = np.zeros_like(frame, dtype=np.uint8)\n",
    "                color_mask[:, :, 0] = color[0] * mask_binary\n",
    "                color_mask[:, :, 1] = color[1] * mask_binary\n",
    "                color_mask[:, :, 2] = color[2] * mask_binary\n",
    "\n",
    "                # 마스크 오버레이\n",
    "                mask_overlay = cv2.addWeighted(mask_overlay, 1, color_mask, 0.5, 0)\n",
    "\n",
    "    # 최종적으로 원본 영상과 마스크를 합성\n",
    "    frame = cv2.addWeighted(frame, 1, mask_overlay, 0.5, 0)\n",
    "\n",
    "    # FPS 계산 및 표시\n",
    "    current_time = time.time()\n",
    "    fps = 1.0 / (current_time - prev_time)\n",
    "    prev_time = current_time\n",
    "    cv2.putText(frame, f\"FPS: {fps:.2f}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    # 화면에 결과 표시\n",
    "    cv2.imshow(window_name, frame)\n",
    "\n",
    "    # ESC 또는 'q' 키를 누르면 종료\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Version: None\n",
      "CUDA Available: False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"CUDA Version:\", torch.version.cuda)\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
