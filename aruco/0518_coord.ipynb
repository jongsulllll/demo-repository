{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import cv2.aruco as aruco\n",
    "import numpy as np\n",
    "import math\n",
    "import rospy\n",
    "from geometry_msgs.msg import Pose2D\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "# ===================== USER PARAMETERS =====================\n",
    "CAM_DEV    = 2               # OpenCV device index\n",
    "FRAME_W    = 1280            # camera resolution\n",
    "FRAME_H    = 720\n",
    "EXPOSURE   = 20              # exposure for low‑light ceilings (‑1 for auto)\n",
    "\n",
    "MARKER_LEN = 0.16           # physical side length of every marker  [m]\n",
    "TARGET_DICT = aruco.DICT_4X4_50\n",
    "\n",
    "# ▶▶▶  사용자가 제공한 천장 마커 월드 좌표 (단위 m)\n",
    "MARKER_WORLD = {\n",
    "    0:  (0.0, 0.0, 0.0),  1:  (1.5, 0.0, 0.0),\n",
    "    2:  (3.0, 0.0, 0.0),  3:  (4.5, 0.0, 0.0),\n",
    "    4:  (0.0, 1.5, 0.0),  5:  (1.5, 1.5, 0.0),\n",
    "    6:  (3.0, 1.5, 0.0),  7:  (4.5, 1.5, 0.0),\n",
    "    8:  (0.0, 3.0, 0.0),  9:  (1.5, 3.0, 0.0),\n",
    "    10: (3.0, 3.0, 0.0), 11: (4.5, 3.0, 0.0),\n",
    "    12: (0.7, 0.7, 0.0), 13: (2.3, 0.7, 0.0),\n",
    "    14: (3.7, 0.7, 0.0), 15: (0.7, 2.3, 0.0),\n",
    "    16: (2.3, 2.3, 0.0), 17: (3.7, 2.3, 0.0),\n",
    "}\n",
    "\n",
    "# ▶▶▶  각 마커가 종이에 인쇄된 방향(시계 +, 단위 deg)\n",
    "MARKER_YAW_DEG = {\n",
    "    0:   0,   1:   0,   2: -180, 3:   0,\n",
    "    4: -180, 5: -180, 6:   0,  7: -180,\n",
    "    8:   0,   9:   0,  10: -180, 11:   0,\n",
    "    12: -180, 13:  -90, 14: -270, 15:   0,\n",
    "    16:  -90, 17:  -90,\n",
    "}\n",
    "\n",
    "# Robot (camera) height w.r.t world frame – DO NOT TOUCH unless ceiling height changes\n",
    "FIXED_Z = -1.9               # [m] ← as requested, same as coord_v10.py\n",
    "# ===========================================================\n",
    "\n",
    "\n",
    "def get_camera_intrinsic():\n",
    "    \"\"\"Load *cameraMatrix* & *distCoeffs* from npz OR use fx,fy,cx,cy placeholders.\"\"\"\n",
    "    try:\n",
    "        npz = np.load(rospy.get_param('~camera_calib_file'))\n",
    "        return npz['cameraMatrix'], npz['distCoeffs']\n",
    "    except Exception:\n",
    "        # --- fallback: pinhole guess ---\n",
    "        fx = fy = 800.0\n",
    "        cx, cy = FRAME_W / 2.0, FRAME_H / 2.0\n",
    "        K  = np.array([[fx,  0, cx],\n",
    "                       [ 0, fy, cy],\n",
    "                       [ 0,  0,  1]])\n",
    "        D  = np.zeros(5)\n",
    "        rospy.logwarn(\"[coord_center_pose] Using dummy intrinsics!\")\n",
    "        return K, D\n",
    "\n",
    "\n",
    "def z_rot(deg: float) -> np.ndarray:\n",
    "    \"\"\"Return 3x3 rotation about +Z by *deg* degrees.\"\"\"\n",
    "    return R.from_euler('z', deg, degrees=True).as_matrix()\n",
    "\n",
    "\n",
    "def main():\n",
    "    rospy.init_node('coord_center_pose')\n",
    "    pose_pub = rospy.Publisher('/robot_pose', Pose2D, queue_size=10)\n",
    "\n",
    "    K, D = get_camera_intrinsic()\n",
    "\n",
    "    cap = cv2.VideoCapture(CAM_DEV)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH,  FRAME_W)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, FRAME_H)\n",
    "    if EXPOSURE >= 0:\n",
    "        cap.set(cv2.CAP_PROP_EXPOSURE, EXPOSURE)\n",
    "\n",
    "    ar_dict  = aruco.getPredefinedDictionary(TARGET_DICT)\n",
    "    ar_param = aruco.DetectorParameters()\n",
    "\n",
    "    rate = rospy.Rate(30)\n",
    "\n",
    "    while not rospy.is_shutdown():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            rate.sleep()\n",
    "            continue\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        corners, ids, _ = aruco.detectMarkers(gray, ar_dict, parameters=ar_param)\n",
    "\n",
    "        if ids is None:\n",
    "            cv2.imshow('aruco', frame)\n",
    "            cv2.waitKey(1)\n",
    "            rate.sleep()\n",
    "            continue\n",
    "\n",
    "        rvecs, tvecs, _ = aruco.estimatePoseSingleMarkers(\n",
    "            corners, MARKER_LEN, K, D\n",
    "        )\n",
    "\n",
    "        world_positions = []\n",
    "        yaws            = []\n",
    "        weights         = []\n",
    "\n",
    "        for rvec, tvec, m_id in zip(rvecs, tvecs, ids.flatten()):\n",
    "            m_id = int(m_id)\n",
    "            if m_id not in MARKER_WORLD:\n",
    "                continue\n",
    "\n",
    "            # camera → marker\n",
    "            R_cm, _ = cv2.Rodrigues(rvec)\n",
    "            p_cm    = tvec.reshape(3)            # marker in camera frame\n",
    "\n",
    "            # marker → world (static)\n",
    "            p_wm    = np.array(MARKER_WORLD[m_id])\n",
    "            R_wm    = z_rot(MARKER_YAW_DEG.get(m_id, 0.0))\n",
    "\n",
    "            # world → camera\n",
    "            R_wc    = R_wm @ R_cm.T\n",
    "            p_wc    = p_wm - R_wc @ p_cm\n",
    "\n",
    "            # 📌  FIXED Z — overrides whatever arithmetic gave us\n",
    "            p_wc[2] = FIXED_Z\n",
    "\n",
    "            # camera (==robot) in world\n",
    "            world_positions.append(p_wc)\n",
    "            yaws.append(R.from_matrix(R_wc).as_euler('xyz', degrees=False)[2])\n",
    "            weights.append(1.0 / (np.linalg.norm(p_cm) + 1e-6))  # nearer marker = higher weight\n",
    "\n",
    "            # draw axis for sanity\n",
    "            aruco.drawAxis(frame, K, D, rvec, tvec, MARKER_LEN * 0.6)\n",
    "\n",
    "        if not world_positions:\n",
    "            cv2.imshow('aruco', frame)\n",
    "            cv2.waitKey(1)\n",
    "            rate.sleep()\n",
    "            continue\n",
    "\n",
    "        W = np.array(weights)\n",
    "        W /= W.sum()\n",
    "\n",
    "        pose_x = float(np.sum([w * p[0] for w, p in zip(W, world_positions)]))\n",
    "        pose_y = float(np.sum([w * p[1] for w, p in zip(W, world_positions)]))\n",
    "        pose_yaw = float(np.arctan2(np.sum(np.sin(yaws)*W),\n",
    "                                    np.sum(np.cos(yaws)*W)))\n",
    "\n",
    "        # Because camera centre == robot centre, we publish directly\n",
    "        msg = Pose2D()\n",
    "        msg.x = pose_x\n",
    "        msg.y = pose_y\n",
    "        msg.theta = pose_yaw\n",
    "        pose_pub.publish(msg)\n",
    "\n",
    "        # HUD\n",
    "        txt = f\"X={pose_x:.2f}  Y={pose_y:.2f}  Yaw={math.degrees(pose_yaw):.1f}°\"\n",
    "        cv2.putText(frame, txt, (30, 70), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    1.8, (0, 0, 255), 3)\n",
    "        cv2.aruco.drawDetectedMarkers(frame, corners, ids)\n",
    "        cv2.imshow('aruco', frame)\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "\n",
    "        rate.sleep()\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        main()\n",
    "    except rospy.ROSInterruptException:\n",
    "        pass\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
